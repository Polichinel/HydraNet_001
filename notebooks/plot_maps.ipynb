{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpd_2023 environment\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "#import seaborn as sns\n",
    "import pickle\n",
    "#import torch\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(test = False):\n",
    "\n",
    "    local_dir_gen = '/home/simon/Documents/scripts/conflictNet/data/generated'\n",
    "    local_dir_pro = '/home/simon/Documents/scripts/conflictNet/data/processed'\n",
    "\n",
    "\n",
    "    if test == False:\n",
    "        with open(f'{local_dir_gen}/posterior_dict_48_calib.pkl', 'rb') as file:\n",
    "            posterior_dict = pickle.load(file)\n",
    "\n",
    "        with open(f'{local_dir_pro}/viewser_monthly_vol_calib_sbnsos.pkl', 'rb') as file: \n",
    "            views_vol = pickle.load(file)\n",
    "            \n",
    "    else:\n",
    "        with open(f'{local_dir_gen}/posterior_dict_36_test.pkl', 'rb') as file:\n",
    "            posterior_dict = pickle.load(file)\n",
    "\n",
    "        with open(f'{local_dir_pro}/viewser_monthly_vol_test_sbnsos.pkl', 'rb') as file: \n",
    "            views_vol = pickle.load(file)\n",
    "\n",
    "    return posterior_dict, views_vol\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT USED YET BELOW!!!! \n",
    "\n",
    "\n",
    "def discard_ME_cells(un_masked_matrix, feature):\n",
    "\n",
    "    # Hard coded...\n",
    "    # For comparison with views 2020 where middle east is not included\n",
    "\n",
    "    # 0 is ocean\n",
    "    # You could load in the views replication data and get the c_id for only africa from there... More kosher\n",
    "    # middle_east_c_id = [\n",
    "    #     0.0, 129.0, 130.0, 131.0, 128.0, 132.0, 133.0, 136.0, 55.0, 60.0, 62.0, 89.0,\n",
    "    #     218.0, 92.0, 220.0, 94.0, 93.0, 96.0, 119.0, 122.0, 124.0, 125.0, 126.0, 127.0\n",
    "    # ]\n",
    "\n",
    "    middle_east_c_id = [0.0]\n",
    "\n",
    "    # Values to mask (0 and 1 in this example)\n",
    "    values_to_mask = np.array(middle_east_c_id)\n",
    "\n",
    "    # Create a mask for the specified values\n",
    "    mask = np.isin(views_vol[-48, :, :, 4], values_to_mask)\n",
    "\n",
    "    # Mask the array using the created mask\n",
    "    masked_matrix = np.ma.masked_where(mask, un_masked_matrix[feature, :, :]) # [feature, :, :] is for the feature, i.e. type of violence\n",
    "\n",
    "    # Get the 1D vector with masked-out values discarded\n",
    "    #vector = masked_matrix.compressed()\n",
    "\n",
    "    return masked_matrix#vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_dict, views_vol = get_data(test = True)\n",
    "\n",
    "posterior_list = posterior_dict['posterior_list']\n",
    "posterior_list_class = posterior_dict['posterior_list_class']\n",
    "out_of_sample_vol = posterior_dict['out_of_sample_vol']\n",
    "\n",
    "test_months = out_of_sample_vol.shape[1]\n",
    "\n",
    "# mean_class_pred = np.array(posterior_list_class[test_months]).mean(axis=0)\n",
    "# mean_pred = np.array(posterior_list[test_months]).mean(axis=0)\n",
    "\n",
    "# mean_class_pred = np.median(np.array(posterior_list_class[test_months]), axis=0)\n",
    "# mean_pred = np.median(np.array(posterior_list[test_months]), axis=0)\n",
    "\n",
    "mean_class_pred = np.percentile(np.array(posterior_list_class[test_months]), 99.9, axis=0)\n",
    "mean_pred = np.percentile(np.array(posterior_list[test_months]), 99.9, axis=0)\n",
    "\n",
    "masked_matrix = discard_ME_cells(mean_class_pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_class_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extent = (-25.75, 63.75, -46.75, 42.75)\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "\n",
    "# Plot the world map\n",
    "world.plot(ax=ax, color='none', edgecolor='black')\n",
    "\n",
    "# Set vmin and vmax for the image\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "\n",
    "\n",
    "ax.imshow(masked_matrix, extent=extent, vmin=vmin, vmax=vmax, cmap='rainbow', alpha=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = masked_matrix.compressed()\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, )\n",
    "\n",
    "# extent = (views_vol[:,:,:,1].min(), views_vol[:,:,:,1].max(), views_vol[:,:,:,2].min(), views_vol[:,:,:,2].max()) \n",
    "extent = (-25.75, 63.75, -46.75, 42.75)\n",
    "\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(30)\n",
    "\n",
    "world.plot(ax = axs[0,0], color='none', edgecolor='black')\n",
    "world.plot(ax = axs[0,1], color='none', edgecolor='black')\n",
    "world.plot(ax = axs[0,2], color='none', edgecolor='black')\n",
    "world.plot(ax = axs[1,0], color='none', edgecolor='black')\n",
    "world.plot(ax = axs[1,1], color='none', edgecolor='black')\n",
    "world.plot(ax = axs[1,2], color='none', edgecolor='black')\n",
    "\n",
    "axs[0,0].imshow(mean_class_pred[0,:,:], extent = extent, cmap='rainbow')\n",
    "axs[0,1].imshow(mean_class_pred[1,:,:], extent = extent, cmap='rainbow')\n",
    "axs[0,2].imshow(mean_class_pred[2,:,:], extent = extent, cmap='rainbow')\n",
    "axs[1,0].imshow(mean_pred[0,:,:], extent = extent, cmap='rainbow')\n",
    "axs[1,1].imshow(mean_pred[1,:,:], extent = extent, cmap='rainbow')\n",
    "axs[1,2].imshow(mean_pred[2,:,:], extent = extent, cmap='rainbow')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert overall ap score.\n",
    "\n",
    "def plt_trio(test_months, posterior_dict, feature_number):\n",
    "    \n",
    "    timelaps_dir = '/home/simon/Documents/scripts/conflictNet/reports/timelapse/feature'\n",
    "\n",
    "    interpolation = 'none'\n",
    "\n",
    "    # extent = (views_vol[:,:,:,1].min(), views_vol[:,:,:,1].max(), views_vol[:,:,:,2].min(), views_vol[:,:,:,2].max())\n",
    "    extent = (-25.75, 63.75, -46.75, 42.75) # hardcode so you do not have to load views_vol\n",
    "\n",
    "#    extent = (-100, 80, -100, 80) \n",
    "\n",
    "\n",
    "    posterior_list = posterior_dict['posterior_list']\n",
    "    posterior_list_class = posterior_dict['posterior_list_class']\n",
    "    out_of_sample_vol = posterior_dict['out_of_sample_vol']\n",
    "\n",
    "    mean_class_pred = np.array(posterior_list_class[test_months]).mean(axis=0)[feature_number,:,:]\n",
    "    mean_pred = np.array(posterior_list[test_months]).mean(axis=0)[feature_number,:,:]\n",
    "    true_obs = out_of_sample_vol[:,test_months,:,:].squeeze()[feature_number,:,:]\n",
    "\n",
    "    std_pred = np.array(posterior_list[test_months]).std(axis=0)[feature_number,:,:]\n",
    "\n",
    "    # min/max for plotting\n",
    "    min_true = out_of_sample_vol[:,0,:,:].min()\n",
    "    max_true = out_of_sample_vol[:,0,:,:].max()\n",
    "    min_pred = np.array(posterior_list).min()\n",
    "    max_pred = np.array(posterior_list).max()\n",
    "    min_pred_class = np.array(posterior_list_class).min()\n",
    "    max_pres_class = np.array(posterior_list_class).max()\n",
    "\n",
    "    min_pred_std = np.array(posterior_list).mean(axis=0).std(axis = 0).min()\n",
    "    max_pred_std = np.array(posterior_list).mean(axis=0).std(axis = 0).max()\n",
    "\n",
    "    all_abs_error = np.abs(out_of_sample_vol[:,0,:,:].squeeze() - np.array(posterior_list).mean(axis = 0))\n",
    "    min_error = all_abs_error.min()\n",
    "    max_error = all_abs_error.max()\n",
    "\n",
    "    # abs error\n",
    "    abs_error = np.abs(true_obs - mean_pred)\n",
    "\n",
    "\n",
    "    # Confucsion\n",
    "    threshold = 0.3 # there is a good way to do this... You have just forgotten it...\n",
    "\n",
    "    binary_pred = (mean_class_pred > threshold) * 1 \n",
    "    binary_true = (true_obs > 0)*1\n",
    "\n",
    "    TP = ((binary_pred == 1) & (binary_true == 1)).astype('int')\n",
    "    FP = ((binary_pred == 1) & (binary_true == 0)).astype('int')*2\n",
    "    FN = ((binary_pred == 0) & (binary_true == 1)).astype('int')*3\n",
    "    # TN = ((binary_pred == 0) & (binary_true == 0)).astype('int')*4\n",
    "\n",
    "\n",
    "    confusion_map = TP + FP + FN #+ TN # TN per defualt 0\n",
    "\n",
    "    # TN gray, TP green, FP blue, FN red\n",
    "    colors = [ (0.5, 0.5, 0.5), (0, 1, 0), (0, 0, 1), (1, 0, 0)]  # R, G, B\n",
    "    cmap_name = 'catagorical4'\n",
    "    cat_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=4)\n",
    "\n",
    "    # plot\n",
    "    #plt.figure(figsize=[30,20])\n",
    "\n",
    "    fig, axs = plt.subplots(2,3, sharey= True, sharex= True)\n",
    "    \n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(30)\n",
    "\n",
    "    plt.subplots_adjust(wspace=-0.01, hspace=-0.2)\n",
    "\n",
    "    axs[0,0].set_title(f'true, month {test_months}')\n",
    "    true_obs_masked =  np.ma.masked_where((views_vol[-48,:,:,4] == 0), true_obs)\n",
    "    world.plot(ax = axs[0,0], color='none', edgecolor='black')\n",
    "    im = axs[0,0].imshow(true_obs_masked, cmap = 'rainbow', vmin= min_true, vmax=max_true, aspect= 'equal', interpolation = interpolation, extent = extent)\n",
    "    plt.colorbar(im, ax = axs[0,0], shrink = 0.6, label = 'observed magnitude y, i.e. log(best)')\n",
    "\n",
    "    axs[0,1].set_title(f'pred, month {test_months}')\n",
    "    mean_pred_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), mean_pred)\n",
    "    world.plot(ax = axs[0,1],color='none', edgecolor='black', figsize = [25,25])\n",
    "    im = axs[0,1].imshow(mean_pred_masked, cmap = 'rainbow', vmin= min_pred, vmax=max_pred, aspect= 'equal', interpolation = interpolation, extent = extent)\n",
    "    plt.colorbar(im, ax = axs[0,1], shrink = 0.6, label = 'predictited magnitude, ŷ ')\n",
    "\n",
    "\n",
    "    axs[0,2].set_title(f'pred class, month {test_months}')\n",
    "    mean_class_pred_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), mean_class_pred)\n",
    "    world.plot(ax = axs[0,2],color='none', edgecolor='black', figsize = [25,25])\n",
    "    im = axs[0,2].imshow(mean_class_pred_masked, cmap = 'rainbow', vmin= min_pred_class, vmax=max_pres_class, aspect= 'equal', interpolation = interpolation, extent = extent)\n",
    "    plt.colorbar(im, ax = axs[0,2], shrink = 0.6, label = 'predictited probability, ỹ')\n",
    "\n",
    "\n",
    "    axs[1,0].set_title(f'absolute error, month {test_months}')\n",
    "    abs_error_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), abs_error)\n",
    "    world.plot(ax = axs[1,0],color='none', edgecolor='black', figsize = [25,25])\n",
    "    im = axs[1,0].imshow(abs_error_masked, cmap = 'rainbow', vmin=min_error, vmax=max_error, aspect= 'equal', interpolation = interpolation, extent = extent) # min and max are not constant here!\n",
    "    plt.colorbar(im, ax = axs[1,0], shrink = 0.6, label = 'absolute error, |y-ŷ|')\n",
    "\n",
    "\n",
    "    axs[1,1].set_title(f'pred std, month {test_months}')  # wonrg title\n",
    "    std_pred_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), std_pred)\n",
    "    world.plot(ax = axs[1,1],color='none', edgecolor='black', figsize = [25,25])\n",
    "    im = axs[1,1].imshow(std_pred_masked, cmap = 'rainbow', vmin=min_pred_std, vmax=max_pred_std, aspect= 'equal', interpolation = interpolation, extent = extent)\n",
    "    plt.colorbar(im, ax = axs[1,1], shrink = 0.6,  label = 'ensemble std (predicted magnitude, ŷ)')\n",
    "\n",
    "\n",
    "    axs[1,2].set_title(f'confusion_map (T=0.3)pred std, month {test_months}')  # wonrg title\n",
    "    confusion_map_masked =  np.ma.masked_where((views_vol[-48,:,:,4] == 0), confusion_map)\n",
    "    world.plot(ax = axs[1,2],color='none', edgecolor='black', figsize = [25,25])\n",
    "    im = axs[1,2].imshow(confusion_map_masked, cmap = cat_cmap, vmin=0, vmax=3, aspect= 'equal', interpolation = interpolation, extent = extent)\n",
    "    cbar = plt.colorbar(im, ax = axs[1,2], ticks = np.linspace(0.4,2.6,4), shrink = 0.6)\n",
    "    cbar.set_ticklabels(['TN', 'TP', 'FP', 'FN'])\n",
    "\n",
    "    #plt.subplots_adjust(hspace = -0.1, wspace = 0.1)\n",
    "\n",
    "    fig_title = f'trio_{str(test_months).zfill(2)}'\n",
    "    plt.savefig(timelaps_dir + str(feature_number) + '/' + fig_title + '.JPG', bbox_inches=\"tight\")\n",
    "    \n",
    "    #plt.show()\n",
    "    \n",
    "    #plt.cla() # idk if this is also needed..\n",
    "    #plt.clf() # idk if this is also needed..\n",
    "    plt.close(fig) # so they do not display or take up mem\n",
    "    #gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt_trio(0, timelaps_dir, posterior_dict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt_trio(0, timelaps_dir, posterior_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt_trio(0, timelaps_dir, posterior_dict, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_months):\n",
    "    plt_trio(i, posterior_dict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_months):\n",
    "    plt_trio(i, posterior_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_months):\n",
    "    plt_trio(i, posterior_dict, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9de4e87321b463199fffea368aacece6dd03deb4f554edc9496f30296d30319d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
