{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# for loss functions\n",
    "#sys.path.insert(0, \"/home/projects/ku_00017/people/simpol/scripts/conflictNet/src/utils\")\n",
    "sys.path.insert(0, \"/home/simon/Documents/scripts/conflictNet/src/utils\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from shrinkage import ShrinkageLoss\n",
    "from stable_balanced_focal_class import stableBalancedFocalLossClass\n",
    "from focal_june import FocalLoss_new\n",
    "\n",
    "from shringkage_june import ShrinkageLoss_new\n",
    "from focal_june import FocalLoss_new\n",
    "\n",
    "\n",
    "# https://d2l.ai/chapter_recurrent-modern/gru.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# attentions is all ... \n",
    "\n",
    "d = 32*32*3 \n",
    "step_num = 600\n",
    "warmup_steps = 100\n",
    "\n",
    "lr_list = []\n",
    "\n",
    "for step_num in range(1, step_num+1):\n",
    "\n",
    "    lr = d**(-0.5) * min(step_num**(-0.5), step_num*warmup_steps**(-1.5))\n",
    "    lr_list.append(lr)\n",
    "\n",
    "plt.vlines(warmup_steps, 0, 0.002, colors='r', linestyles='dashed')\n",
    "plt.hlines(0.001, 0, step_num, colors='r', linestyles='dashed')\n",
    "plt.plot(lr_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_p = nn.BCELoss()\n",
    "criterion_l = nn.BCEWithLogitsLoss()\n",
    "\n",
    "criterion_focal01 = stableBalancedFocalLossClass(gamma=0, alpha=0.5) # gamma=0 no weights, alpha=0.5 even weights\n",
    "criterion_focal02 = FocalLoss_new(gamma=1, alpha=0.5) # gamma=0 no weights, alpha=0.5 even weights\n",
    "\n",
    "shringkage = ShrinkageLoss_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary ground truth labels (0 or 1) with thousands of entries\n",
    "num_samples = 100000\n",
    "y = torch.randint(0, 2, (num_samples,), dtype=torch.float32)\n",
    "\n",
    "# Generate predicted logits or probabilities with the same shape as y\n",
    "# For testing purposes, I'm using random values here.\n",
    "# You can replace this with your actual predicted logits or probabilities.\n",
    "y_hat_logits = torch.randn((num_samples,), dtype=torch.float32)\n",
    "\n",
    "# Optionally, you can normalize logits to probabilities using sigmoid for binary classification\n",
    "y_hat_probs = torch.sigmoid(y_hat_logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7982)\n",
      "tensor(0.7982)\n",
      "tensor(nan)\n",
      "tensor(3140.0649)\n"
     ]
    }
   ],
   "source": [
    "print(criterion_p(y_hat_probs, y))\n",
    "print(criterion_l(y_hat_logits, y))\n",
    "\n",
    "print(criterion_focal01(y_hat_logits, y))\n",
    "print(criterion_focal02(y_hat_logits, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39.5226)\n"
     ]
    }
   ],
   "source": [
    "# Generate ground truth value (0 to 9) with thousands of entries\n",
    "num_samples = 100000\n",
    "y = torch.randint(0, 10, (num_samples,), dtype=torch.float32)\n",
    "\n",
    "y_hat = F.relu(torch.randn(num_samples, dtype=torch.float32) + 5 * 2 ) # 5 is the mean, 2 is the std\n",
    "\n",
    "print(shringkage(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(1,21,[5,5,5])\n",
    "X_tensor = torch.from_numpy(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(1,21,[5,5,5])\n",
    "X_tensor = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "criterion_class = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            weight=None,\n",
    "            gamma=2.0,\n",
    "            reduction='mean'\n",
    "    ):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = torch.sigmoid(input_tensor)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        term = ((1.0 - prob) ** self.gamma) * log_prob\n",
    "        return F.nll_loss(term, target_tensor)\n",
    "        \n",
    "        #return F.nll_loss(term, target_tensor, weight=self.weight, reduction=self.reduction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss01(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, weight=None, size_average=True):\n",
    "        super(FocalLoss01, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.contiguous().view(input.size(0), input.size(1), -1)\n",
    "            input = input.transpose(1,2)\n",
    "            input = input.contiguous().view(-1, input.size(2)).squeeze()\n",
    "        if target.dim()==4:\n",
    "            target = target.contiguous().view(target.size(0), target.size(1), -1)\n",
    "            target = target.transpose(1,2)\n",
    "            target = target.contiguous().view(-1, target.size(2)).squeeze()\n",
    "        elif target.dim()==3:\n",
    "            target = target.view(-1)\n",
    "        else:\n",
    "            target = target.view(-1, 1)\n",
    "\n",
    "        # compute the negative likelyhood\n",
    "        weight = Variable(self.weight)\n",
    "        logpt = -F.cross_entropy(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = -((1-pt)**self.gamma) * logpt\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss02(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, weight=None, size_average=True):\n",
    "        super(FocalLoss02, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # if input.dim()>2:\n",
    "        #     input = input.contiguous().view(input.size(0), input.size(1), -1)\n",
    "        #     input = input.transpose(1,2)\n",
    "        #     input = input.contiguous().view(-1, input.size(2)).squeeze()\n",
    "        # if target.dim()==4:\n",
    "        #     target = target.contiguous().view(target.size(0), target.size(1), -1)\n",
    "        #     target = target.transpose(1,2)\n",
    "        #     target = target.contiguous().view(-1, target.size(2)).squeeze()\n",
    "        # elif target.dim()==3:\n",
    "        #     target = target.view(-1)\n",
    "        # else:\n",
    "        #     target = target.view(-1, 1)\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        # compute.unsqueeze(0)F.cross_entropy(input, target)\n",
    "        logpt = -F.cross_entropy(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = -((1-pt)**self.gamma) * logpt\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss03(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss03, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        # compute.unsqueeze(0)F.cross_entropy(input, target)\n",
    "        p = 1/(1+np.exp(-input))\n",
    "        loss = -( self.alpha*target + (1-self.alpha)*(1-target) ) * (( 1 - ( target*p + (1-target)*(1-p)) )**self.gamma) * ( target*np.log(p)+(1-target)*np.log(1-p) )\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss04(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss04, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        loss = -(target * np.log(input) + (1-target) * np.log(1-input)) #BCE\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss05(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss05, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * np.log(input) + (1-target) * np.log(1-input))\n",
    "        loss = -self.alpha * ((1-np.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST!!!\n",
    "\n",
    "class FocalLoss05(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss05, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * np.log(input) + (1-target) * np.log(1-input))\n",
    "        loss = -self.alpha * ((1-np.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossClass(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLossClass, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * torch.log(input) + (1-target) * torch.log(1-input))\n",
    "        loss = -self.alpha * ((1-torch.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #WORKS!\n",
    "# class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "#     def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "#         super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.size_average = size_average\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "\n",
    "#         input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "#         input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "\n",
    "#         pos = (-self.alpha * (1-input)**self.gamma * torch.log(input))\n",
    "#         neg = (-(1-self.alpha) * (1-1-input)**self.gamma *  torch.log(1-input))\n",
    "\n",
    "#         #pos = ( (1-input)**self.gamma * torch.log(input))\n",
    "#         #neg = ( (input)**self.gamma *  torch.log(1-input))\n",
    "\n",
    "#         loss = -(pos * target + neg * (1-target))\n",
    "\n",
    "#         # averaging (or not) loss\n",
    "#         if self.size_average:\n",
    "#             return loss.mean()\n",
    "#         else:\n",
    "#             return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "#     def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "#         super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.size_average = size_average\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "\n",
    "#         input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        \n",
    "\n",
    "#         #for logits\n",
    "#         # pos = (-self.alpha * (1-F.sigmoid(input))**self.gamma * F.logsigmoid(input))\n",
    "#         # neg = (-(1-self.alpha) * (-F.sigmoid(input))**self.gamma *  F.logsigmoid(1-input))\n",
    "#         # loss = (pos * target + neg * (1-target))\n",
    "\n",
    "#         # for probs\n",
    "#         input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "#         pos = (-self.alpha * (1-input)**self.gamma * torch.log(input))\n",
    "#         neg = (-(1-self.alpha) * (1-1-input)**self.gamma *  torch.log(1-input))\n",
    "#         loss = (pos * target + neg * (1-target))\n",
    "\n",
    "#         # averaging (or not) loss\n",
    "#         if self.size_average:\n",
    "#             return loss.mean()\n",
    "#         else:\n",
    "#             return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class stableBalancedFocalLossClass(nn.Module):\n",
    "\n",
    "#     def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "#         super(stableBalancedFocalLossClass, self).__init__()\n",
    "\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.size_average = size_average\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "\n",
    "#         input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "#         # fo   r probs\n",
    "#         min_ind = torch.exp(torch.tensor(-100)) # almost 0\n",
    "#         max_ind = torch.tensor(1.0)- torch.exp(torch.tensor(-10)) # almost 1\n",
    "#         input = torch.clamp(input, min = min_ind, max = max_ind) # so we do not log(0)\n",
    "\n",
    "#         pos = (-self.alpha * (1-input)**self.gamma * torch.log(input))\n",
    "#         neg = (-(1-self.alpha) * (1-1-input)**self.gamma *  torch.log(1-input))\n",
    "#         loss = (pos * target + neg * (1-target))\n",
    "\n",
    "#         # Seem pytorch have something like this..\n",
    "#         if loss.mean() >= max_ind:\n",
    "#             floor = 10\n",
    "#         else:\n",
    "#             floor = 1\n",
    "\n",
    "#         loss =  loss * 2 * floor # *2 is just a constant to make it more like BCE\n",
    "\n",
    "#         # averaging (or not) lossinput = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "        \n",
    "#         if self.size_average:\n",
    "#             return loss.mean()\n",
    "#         else:\n",
    "#             return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(p):\n",
    "    return (p * np.log(1/p)).sum()\n",
    "\n",
    "def cross_entropy(p, q):\n",
    "    return -(p * np.log(q)).sum() # same as (p * np.log(1/q)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "        super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        \n",
    "        # Numerical stabilityt pytorhc trick.\n",
    "        log_input = torch.clamp(torch.log(input), -100, 100)\n",
    "        log_input_rev = torch.clamp(torch.log(1-input), -100, 100)\n",
    "\n",
    "        # for probs\n",
    "        pos = (-self.alpha * (1-input)**self.gamma * log_input)\n",
    "        neg = (-(1-self.alpha) * (1-1-input)**self.gamma * log_input_rev)\n",
    "        \n",
    "        loss = (pos * target + neg * (1-target))\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_class = nn.BCELoss()\n",
    "\n",
    "x1 = torch.rand([ 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion_focal01 = FocalLoss01(gamma=1)\n",
    "# criterion_focal02 = FocalLoss02(gamma=1, size_average=False)\n",
    "# criterion_focal03 = FocalLoss03(gamma=1, alpha = 1, size_average=True)\n",
    "\n",
    "# criterion_focal04 = FocalLoss04(gamma=0)\n",
    "# criterion_focal05 = FocalLoss05()\n",
    "\n",
    "#criterion_focal06 = FocalLossClass()\n",
    "criterion_focal07 = BalancedFocalLossClass(gamma=2, alpha=0.05)\n",
    "# criterion_focal07 = stableBalancedFocalLossClass(gamma=0, alpha=0.5)\n",
    "\n",
    "\n",
    "# print(criterion_focal01(x1.unsqueeze(0), x1_b.unsqueeze(0)))\n",
    "# print(criterion_focal02(x1, x1_b))\n",
    "# print(criterion_focal03(x1, x1_b))\n",
    "\n",
    "\n",
    "# print(criterion_focal04(x1, x1_b))\n",
    "\n",
    "# print(criterion_focal05(x1, x1_b))\n",
    "\n",
    "#print(criterion_focal06(x1, x1_b))\n",
    "\n",
    "print(criterion_focal07(x1, x1_b)) \n",
    "\n",
    "\n",
    "print(criterion_class(x1, x1_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal07 = BalancedFocalLossClass(gamma=0, alpha=0.5)\n",
    "\n",
    "print(criterion_focal07(x1, x1_b)) \n",
    "print(criterion_class(x1, x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([ 3 ,100, 100]) \n",
    "\n",
    "x2 = torch.zeros([ 3 ,100, 100]) + torch.tensor(1.0) - torch.exp(torch.tensor(0))\n",
    "\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "\n",
    "print(criterion_focal07(x2, x1_b)*2) \n",
    "print(criterion_class(x2, x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([ 3 ,100, 100]) \n",
    "\n",
    "x2 = torch.zeros([ 3 ,100, 100]) + torch.tensor(1.0) - torch.exp(torch.tensor(-12))\n",
    "\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "if x2.mean() > torch.tensor(1.0) - torch.exp(torch.tensor(-15)):\n",
    "    floor = 10\n",
    "else:\n",
    "    floor = 1\n",
    "\n",
    "print(criterion_focal07(x2, x1_b) * floor) \n",
    "print(criterion_class(x2, x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_class01 = BalancedFocalLossClass(gamma=0.0, alpha=0.75)\n",
    "criterion_focal_class02 = BalancedFocalLossClass(gamma=2.0, alpha=0.25)\n",
    "criterion_focal_class03 = BalancedFocalLossClass(gamma=5.0, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'focal, gamma = 0, alpha = 1 : \\t {criterion_focal_class01(x1, x1_b)}')\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_class02(x1, x1_b)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_class03(x1, x1_b)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.logsigmoid(torch.tensor(.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32)\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "RT = torch.rand([ 3 ,100, 100]) \n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BalancedFocalLossClass(gamma=2, alpha=0.95)\n",
    "\n",
    "\n",
    "print(criterion(ZT, IT)) \n",
    "print(criterion(RT, IT)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss_reg, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        mse = (target - input)**2\n",
    "\n",
    "        loss = self.alpha * ((1-np.exp(mse))**self.gamma) * mse # for gamma = 0 and alpha = 1 we get the mse\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "\n",
    "x1 = torch.rand([ 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg01 = FocalLoss_reg(gamma=0)\n",
    "criterion_focal_reg02 = FocalLoss_reg(gamma=1)\n",
    "criterion_focal_reg03 = FocalLoss_reg(gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32)\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "OT = torch.zeros([ 3 ,100, 100]) + 1\n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: \\t\\t\\t\\t {criterion_reg(ZT, IT)}')\n",
    "print(f'focal, gamma = 0, alpha = 1 : \\t {criterion_focal_reg01(ZT, IT)}')\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_reg02(ZT, IT)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_reg03(ZT, IT)}')\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_reg01(OT, IT)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_reg02(OT, IT)}')\n",
    "print(f'focal, gamma = 3, alpha = 1 : \\t {criterion_focal_reg03(OT, IT)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(input, target):\n",
    "    loss = (target - input)**2\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(input, target):\n",
    "    se = target - input\n",
    "    lse = np.exp(se)  #torch.clamp(se, min = np.exp(-100)))\n",
    "    mlse = lse.mean()\n",
    "\n",
    "    return mlse\n",
    "\n",
    "    # return - np.log(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand([ 3 ,100, 100]) * 10\n",
    "\n",
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32) * noise\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "OT = (torch.zeros([ 3 ,100, 100]) + 1 ) * noise\n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE(ZT, IT))\n",
    "print(MSE(OT, IT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OT.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss_reg, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        #input = torch.clamp(input, min = np.exp(-100)) # could do this for no negatives???\n",
    "\n",
    "        error = target - input\n",
    "        exp_error = np.exp(error)  #torch.clamp(se, min = np.exp(-100)))\n",
    "        loss = exp_error.mean()\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShrinkageLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, a=10, c=0.2, size_average=True):\n",
    "        super(ShrinkageLoss, self).__init__()\n",
    "\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0) \n",
    "\n",
    "        l = torch.abs(target - input)     #F.l1_loss(input, target)\n",
    "\n",
    "        loss = (l**2)/(1 + torch.exp(self.a*(self.c-l)))\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg = ShrinkageLoss(a=10, c=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg = ShrinkageLoss(a=1, c=12)\n",
    "\n",
    "print(criterion_focal_reg(ZT, IT))\n",
    "print(criterion_focal_reg(OT, IT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shannon_entropy(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy( x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-(x1_b * np.log(x1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1_b * (np.log(1/x1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion_focal02(x1, x1_b))\n",
    "print(criterion_class(x1, x1_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 3\n",
    "\n",
    "if t == 1 or t == 0:\n",
    "    print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = RMSLELoss()\n",
    "print(f'sgoairb: {cr}\\n..................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([3,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal = FocalLoss2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion_focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal(x1.unsqueeze(0), x1_b.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "sigmoid_focal_loss(x1, x1_b, reduction= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])#.type(torch.LongTensor)\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "criterion_focal(x1.reshape(-1), x1_b.reshape(-1).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "#x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x2 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "x3 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x4 = torch.randn([1, 3 ,100, 100]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1_ = x1.reshape(-1)\n",
    "# x2_ = x2.reshape(-1)\n",
    "\n",
    "# mask = x1_ > 0\n",
    "\n",
    "# x1_[mask].shape\n",
    "\n",
    "# criterion_reg(x1_, x2_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(losses_list) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    x1_ = x1[:,i,:,:].reshape(-1)\n",
    "    x2_ = x2[:,i,:,:].reshape(-1)\n",
    "    mask = (x3[:,i,:,:].reshape(-1) > 0.0001) | (x4[:,i,:,:].reshape(-1) > 0.0001)\n",
    "\n",
    "    losses_list.append(criterion_reg(x1_[mask], x2_[mask]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    losses_list.append(criterion_class(t1_pred_class[:,i,:,:], t1_binary[:,i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    losses_list.append(torch.tensor(1.0))\n",
    "\n",
    "for i in range(3):\n",
    "    losses_list.append(torch.tensor(2.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.stack(losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[-3:].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 32\n",
    "D = 16 \n",
    "\n",
    "\n",
    "X = torch.rand(1, 3, D, D)\n",
    "H = torch.rand(1, hidden_channels, D, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H+X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c2 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c3 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c4 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c5 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c6 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.sigmoid(c1(X) + c2(H))\n",
    "\n",
    "R = torch.sigmoid(c3(X) + c4(H))\n",
    "\n",
    "H_tilde = torch.tanh(c5(X) + c6(torch.mul(R,H)))\n",
    "\n",
    "H = torch.mul(torch.mul(Z,H) + (1 - Z), H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.zeros([1,48,3,180,180])\n",
    "tens  =torch.tensor(vol)\n",
    "\n",
    "torch.stack((tens,tens)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.zeros([1,48,3,180,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[:,:,0,:,:] = 1\n",
    "vol[:,:,1,:,:] = 2\n",
    "vol[:,:,2,:,:] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol.shape)\n",
    "print(vol[:,:,0,:,:].mean())\n",
    "print(vol[:,:,1,:,:].mean())\n",
    "print(vol[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = vol.shape[0] # batch size. Always 1\n",
    "C = vol.shape[1] # months\n",
    "D = vol.shape[2] # features\n",
    "H = vol.shape[3] # height\n",
    "W = vol.shape[4] # width\n",
    "\n",
    "vol2 = vol.reshape(N, C*D, H, W)\n",
    "print(vol2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = transforms.Compose([transforms.RandomRotation((0,360)), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])\n",
    "transformer = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation (can be turned of for final experiments)        \n",
    "vol2 = transformer(torch.tensor(vol2)) # rotations and flips # skip for now... '''''''''''''''''''''''''''''''''''''''''''''''''''''' bug only take 4 dims.. could just squezze the batrhc dom and then give it again afterwards?#train_tensor = train_tensor.reshape(N, C, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol3 = vol2.reshape(N,C,D,H,W)\n",
    "print(vol3.shape)\n",
    "print(vol3[:,:,0,:,:].mean())\n",
    "print(vol3[:,:,1,:,:].mean())\n",
    "print(vol3[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(vol3 == vol).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e07914b3d36b3c0ae84e5e97633abec307a3dfe696e94a6042eabf44e48503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
