{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# https://d2l.ai/chapter_recurrent-modern/gru.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "criterion_class = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            weight=None,\n",
    "            gamma=2.0,\n",
    "            reduction='mean'\n",
    "    ):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = torch.sigmoid(input_tensor)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        term = ((1.0 - prob) ** self.gamma) * log_prob\n",
    "        return F.nll_loss(term, target_tensor)\n",
    "        \n",
    "        #return F.nll_loss(term, target_tensor, weight=self.weight, reduction=self.reduction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2466)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])#.type(torch.LongTensor)\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "criterion_focal(x1.reshape(-1), x1_b.reshape(-1).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3178)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "#x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x2 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "x3 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x4 = torch.randn([1, 3 ,100, 100]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9961)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x1_ = x1.reshape(-1)\n",
    "# x2_ = x2.reshape(-1)\n",
    "\n",
    "# mask = x1_ > 0\n",
    "\n",
    "# x1_[mask].shape\n",
    "\n",
    "# criterion_reg(x1_, x2_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(losses_list) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    x1_ = x1[:,i,:,:].reshape(-1)\n",
    "    x2_ = x2[:,i,:,:].reshape(-1)\n",
    "    mask = (x3[:,i,:,:].reshape(-1) > 0.0001) | (x4[:,i,:,:].reshape(-1) > 0.0001)\n",
    "\n",
    "    losses_list.append(criterion_reg(x1_[mask], x2_[mask]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(2.0036), tensor(1.9821), tensor(1.9411)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    losses_list.append(criterion_class(t1_pred_class[:,i,:,:], t1_binary[:,i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    losses_list.append(torch.tensor(1.0))\n",
    "\n",
    "for i in range(3):\n",
    "    losses_list.append(torch.tensor(2.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.stack(losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[-3:].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(2.)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 32\n",
    "D = 16 \n",
    "\n",
    "\n",
    "X = torch.rand(1, 3, D, D)\n",
    "H = torch.rand(1, hidden_channels, D, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m H\u001b[39m+\u001b[39;49mX\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "H+X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c2 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c3 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c4 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c5 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c6 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.sigmoid(c1(X) + c2(H))\n",
    "\n",
    "R = torch.sigmoid(c3(X) + c4(H))\n",
    "\n",
    "H_tilde = torch.tanh(c5(X) + c6(torch.mul(R,H)))\n",
    "\n",
    "H = torch.mul(torch.mul(Z,H) + (1 - Z), H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 16, 16])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 48, 3, 180, 180])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = np.zeros([1,48,3,180,180])\n",
    "tens  =torch.tensor(vol)\n",
    "\n",
    "torch.stack((tens,tens)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.zeros([1,48,3,180,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[:,:,0,:,:] = 1\n",
    "vol[:,:,1,:,:] = 2\n",
    "vol[:,:,2,:,:] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 3, 180, 180)\n",
      "1.0\n",
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(vol.shape)\n",
    "print(vol[:,:,0,:,:].mean())\n",
    "print(vol[:,:,1,:,:].mean())\n",
    "print(vol[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 144, 180, 180)\n"
     ]
    }
   ],
   "source": [
    "N = vol.shape[0] # batch size. Always 1\n",
    "C = vol.shape[1] # months\n",
    "D = vol.shape[2] # features\n",
    "H = vol.shape[3] # height\n",
    "W = vol.shape[4] # width\n",
    "\n",
    "vol2 = vol.reshape(N, C*D, H, W)\n",
    "print(vol2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = transforms.Compose([transforms.RandomRotation((0,360)), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])\n",
    "transformer = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation (can be turned of for final experiments)        \n",
    "vol2 = transformer(torch.tensor(vol2)) # rotations and flips # skip for now... '''''''''''''''''''''''''''''''''''''''''''''''''''''' bug only take 4 dims.. could just squezze the batrhc dom and then give it again afterwards?#train_tensor = train_tensor.reshape(N, C, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48, 3, 180, 180])\n",
      "tensor(1., dtype=torch.float64)\n",
      "tensor(2., dtype=torch.float64)\n",
      "tensor(3., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "vol3 = vol2.reshape(N,C,D,H,W)\n",
    "print(vol3.shape)\n",
    "print(vol3[:,:,0,:,:].mean())\n",
    "print(vol3[:,:,1,:,:].mean())\n",
    "print(vol3[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vol3 == vol).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e07914b3d36b3c0ae84e5e97633abec307a3dfe696e94a6042eabf44e48503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
