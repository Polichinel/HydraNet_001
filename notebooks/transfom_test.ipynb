{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# https://d2l.ai/chapter_recurrent-modern/gru.html\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.73105858, 0.88079708, 0.95257413, 0.98201379,\n",
       "       0.99330715, 0.99752738, 0.99908895, 0.99966465, 0.99987661,\n",
       "       0.9999546 , 0.9999833 , 0.99999386, 0.99999774, 0.99999917,\n",
       "       0.99999969, 0.99999989, 0.99999996, 0.99999998, 0.99999999,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(1/(1 + np.exp(-sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.        ,  5.90616109,  4.76505358,  4.19059784,  3.83224293,\n",
       "        3.58197048,  3.39453666,  3.24734205,  3.12771273,  3.02793107,\n",
       "        2.9429983 ,  2.86951732,  2.80508894,  2.7479644 ,  2.69683512,\n",
       "        2.65069975,  2.60877731,  2.57044844,  2.53521478,  2.50267018,\n",
       "        2.47247979,  2.44436476,  2.41809067,  2.39345887,  2.37029968,\n",
       "        2.34846719,  2.32783514,  2.30829361,  2.28974642,  2.27210896,\n",
       "        2.25530646,  2.23927259,  2.22394822,  2.20928049,  2.19522194,\n",
       "        2.18172983,  2.16876557,  2.15629417,  2.14428387,  2.13270571,\n",
       "        2.12153328,  2.11074237,  2.10031079,  2.09021815,  2.08044564,\n",
       "        2.07097591,  2.06179292,  2.05288182,  2.04422881,  2.03582108,\n",
       "        2.02764671,  2.01969456,  2.01195426,  2.00441611,  1.99707102,\n",
       "        1.98991048,  1.9829265 ,  1.97611157,  1.96945864,  1.96296106,\n",
       "        1.95661256,  1.95040724,  1.9443395 ,  1.93840408,  1.93259597,\n",
       "        1.92691046,  1.92134305,  1.9158895 ,  1.91054576,  1.90530801,\n",
       "        1.90017258,  1.89513601,  1.890195  ,  1.88534639,  1.88058718,\n",
       "        1.87591451,  1.87132562,  1.86681791,  1.86238889,  1.85803614,\n",
       "        1.85375739,  1.84955045,  1.8454132 ,  1.84134365,  1.83733984,\n",
       "        1.83339994,  1.82952215,  1.82570478,  1.82194617,  1.81824474,\n",
       "        1.81459897,  1.8110074 ,  1.80746863,  1.80398128,  1.80054405,\n",
       "        1.79715569,  1.79381497,  1.79052072,  1.78727181,  1.78406715,\n",
       "        1.78090568,  1.77778637,  1.77470825,  1.77167035,  1.76867176,\n",
       "        1.76571158,  1.76278895,  1.75990304,  1.75705302,  1.75423813,\n",
       "        1.75145759,  1.74871067,  1.74599666,  1.74331486,  1.7406646 ,\n",
       "        1.73804523,  1.73545612,  1.73289664,  1.73036621,  1.72786424,\n",
       "        1.72539016,  1.72294344,  1.72052354,  1.71812994,  1.71576213,\n",
       "        1.71341963,  1.71110196,  1.70880866,  1.70653927,  1.70429336,\n",
       "        1.70207049,  1.69987025,  1.69769224,  1.69553605,  1.6934013 ,\n",
       "        1.69128762,  1.68919463,  1.68712198,  1.68506933,  1.68303632,\n",
       "        1.68102263,  1.67902793,  1.67705191,  1.67509426,  1.67315467,\n",
       "        1.67123286,  1.66932853,  1.6674414 ,  1.66557119,  1.66371765,\n",
       "        1.6618805 ,  1.66005949,  1.65825436,  1.65646489,  1.65469081,\n",
       "        1.6529319 ,  1.65118793,  1.64945868,  1.64774392,  1.64604344,\n",
       "        1.64435703,  1.64268448,  1.64102559,  1.63938016,  1.637748  ,\n",
       "        1.63612892,  1.63452274,  1.63292927,  1.63134832,  1.62977974,\n",
       "        1.62822335,  1.62667897,  1.62514645,  1.62362562,  1.62211633,\n",
       "        1.62061842,  1.61913173,  1.61765612,  1.61619144,  1.61473755,\n",
       "        1.61329431,  1.61186158,  1.61043921,  1.60902709,  1.60762508,\n",
       "        1.60623304,  1.60485086,  1.6034784 ,  1.60211556,  1.6007622 ,\n",
       "        1.59941821,  1.59808348,  1.59675789,  1.59544134,  1.5941337 ,\n",
       "        1.59283488,  1.59154476,  1.59026326,  1.58899025,  1.58772564,\n",
       "        1.58646934,  1.58522125,  1.58398127,  1.5827493 ,  1.58152526,\n",
       "        1.58030905,  1.57910059,  1.57789979,  1.57670656,  1.57552081,\n",
       "        1.57434247,  1.57317144,  1.57200766,  1.57085103,  1.56970149,\n",
       "        1.56855895,  1.56742334,  1.56629458,  1.5651726 ,  1.56405733,\n",
       "        1.56294869,  1.56184662,  1.56075104,  1.55966189,  1.5585791 ,\n",
       "        1.55750261,  1.55643234,  1.55536824,  1.55431024,  1.55325828,\n",
       "        1.5522123 ,  1.55117223,  1.55013802,  1.54910961,  1.54808694,\n",
       "        1.54706996,  1.5460586 ,  1.54505281,  1.54405254,  1.54305773,\n",
       "        1.54206833,  1.54108429,  1.54010556,  1.53913207,  1.53816379,\n",
       "        1.53720067,  1.53624265,  1.53528969,  1.53434174,  1.53339875,\n",
       "        1.53246067,  1.53152747,  1.53059909,  1.52967549,  1.52875663,\n",
       "        1.52784246,  1.52693294,  1.52602803,  1.52512768,  1.52423187,\n",
       "        1.52334053,  1.52245364,  1.52157115,  1.52069304,  1.51981924,\n",
       "        1.51894974,  1.51808449,  1.51722345,  1.51636659,  1.51551387,\n",
       "        1.51466526,  1.51382071,  1.51298021,  1.5121437 ,  1.51131116,\n",
       "        1.51048255,  1.50965785,  1.50883701,  1.50802   ,  1.5072068 ,\n",
       "        1.50639737,  1.50559168,  1.50478969,  1.50399139,  1.50319673,\n",
       "        1.50240569,  1.50161825,  1.50083436,  1.500054  ,  1.49927714,\n",
       "        1.49850376,  1.49773382,  1.49696731,  1.49620418,  1.49544442,\n",
       "        1.494688  ,  1.49393489,  1.49318507,  1.49243851,  1.49169518,\n",
       "        1.49095506,  1.49021813,  1.48948436,  1.48875372,  1.4880262 ,\n",
       "        1.48730177,  1.4865804 ,  1.48586207,  1.48514676,  1.48443445,\n",
       "        1.48372511,  1.48301873,  1.48231527,  1.48161472,  1.48091706,\n",
       "        1.48022226,  1.4795303 ,  1.47884117,  1.47815484,  1.4774713 ,\n",
       "        1.47679051,  1.47611247,  1.47543715,  1.47476453,  1.47409459,\n",
       "        1.47342732,  1.47276269,  1.47210069,  1.47144129,  1.47078449,\n",
       "        1.47013025,  1.46947857,  1.46882942,  1.46818279,  1.46753866,\n",
       "        1.46689701,  1.46625783,  1.4656211 ,  1.46498679,  1.4643549 ,\n",
       "        1.46372541,  1.4630983 ,  1.46247356,  1.46185117,  1.46123111,\n",
       "        1.46061337,  1.45999793,  1.45938478,  1.4587739 ,  1.45816528,\n",
       "        1.4575589 ,  1.45695474,  1.4563528 ,  1.45575306,  1.4551555 ,\n",
       "        1.45456011,  1.45396687,  1.45337578,  1.45278681,  1.45219996,\n",
       "        1.45161521,  1.45103254,  1.45045194,  1.44987341,  1.44929692,\n",
       "        1.44872247,  1.44815003,  1.44757961,  1.44701118,  1.44644473,\n",
       "        1.44588025,  1.44531774,  1.44475716,  1.44419852,  1.44364181,\n",
       "        1.443087  ,  1.44253409,  1.44198307,  1.44143392,  1.44088663,\n",
       "        1.4403412 ,  1.43979761,  1.43925585,  1.43871591,  1.43817777,\n",
       "        1.43764143,  1.43710688,  1.4365741 ,  1.43604309,  1.43551383,\n",
       "        1.43498632,  1.43446054,  1.43393648,  1.43341413,  1.43289349,\n",
       "        1.43237454,  1.43185728,  1.43134169,  1.43082776,  1.43031548,\n",
       "        1.42980485,  1.42929586,  1.42878849,  1.42828274,  1.42777859,\n",
       "        1.42727604,  1.42677508,  1.4262757 ,  1.42577789,  1.42528164,\n",
       "        1.42478695,  1.4242938 ,  1.42380218,  1.42331209,  1.42282352,\n",
       "        1.42233646,  1.4218509 ,  1.42136684,  1.42088426,  1.42040315,\n",
       "        1.41992352,  1.41944535,  1.41896862,  1.41849335,  1.41801951,\n",
       "        1.41754709,  1.4170761 ,  1.41660653,  1.41613836,  1.41567158,\n",
       "        1.4152062 ,  1.4147422 ,  1.41427958,  1.41381833,  1.41335844,\n",
       "        1.4128999 ,  1.41244271,  1.41198685,  1.41153234,  1.41107914,\n",
       "        1.41062727,  1.4101767 ,  1.40972745,  1.40927949,  1.40883282,\n",
       "        1.40838744,  1.40794333,  1.4075005 ,  1.40705893,  1.40661862,\n",
       "        1.40617956,  1.40574174,  1.40530517,  1.40486983,  1.40443572,\n",
       "        1.40400282,  1.40357114,  1.40314067,  1.4027114 ,  1.40228333,\n",
       "        1.40185644,  1.40143074,  1.40100622,  1.40058287,  1.40016069,\n",
       "        1.39973966,  1.3993198 ,  1.39890108,  1.3984835 ,  1.39806706,\n",
       "        1.39765176,  1.39723758,  1.39682452,  1.39641258,  1.39600175,\n",
       "        1.39559202,  1.3951834 ,  1.39477586,  1.39436942,  1.39396406,\n",
       "        1.39355978,  1.39315657,  1.39275443,  1.39235335,  1.39195333,\n",
       "        1.39155437,  1.39115645,  1.39075958,  1.39036374,  1.38996894,\n",
       "        1.38957516,  1.38918241,  1.38879068,  1.38839996,  1.38801025,\n",
       "        1.38762154,  1.38723384,  1.38684713,  1.38646141,  1.38607667,\n",
       "        1.38569292,  1.38531015,  1.38492835,  1.38454751,  1.38416764,\n",
       "        1.38378873,  1.38341077,  1.38303377,  1.38265771,  1.38228259,\n",
       "        1.38190841,  1.38153516,  1.38116285,  1.38079145,  1.38042098,\n",
       "        1.38005143,  1.37968279,  1.37931505,  1.37894823,  1.3785823 ,\n",
       "        1.37821727,  1.37785313,  1.37748988,  1.37712752,  1.37676603,\n",
       "        1.37640542,  1.37604569,  1.37568683,  1.37532883,  1.37497169,\n",
       "        1.37461541,  1.37425999,  1.37390542,  1.37355169,  1.37319881,\n",
       "        1.37284676,  1.37249556,  1.37214518,  1.37179563,  1.37144691,\n",
       "        1.37109902,  1.37075194,  1.37040567,  1.37006022,  1.36971557,\n",
       "        1.36937173,  1.36902869,  1.36868645,  1.36834501,  1.36800435,\n",
       "        1.36766448,  1.3673254 ,  1.3669871 ,  1.36664957,  1.36631283,\n",
       "        1.36597685,  1.36564164,  1.3653072 ,  1.36497352,  1.36464059,\n",
       "        1.36430843,  1.36397701,  1.36364635,  1.36331643,  1.36298726,\n",
       "        1.36265883,  1.36233113,  1.36200417,  1.36167794,  1.36135244,\n",
       "        1.36102767,  1.36070362,  1.36038028,  1.36005767,  1.35973577,\n",
       "        1.35941458,  1.3590941 ,  1.35877432,  1.35845525,  1.35813688,\n",
       "        1.3578192 ,  1.35750222,  1.35718593,  1.35687033,  1.35655542,\n",
       "        1.35624119,  1.35592764,  1.35561477,  1.35530257,  1.35499105,\n",
       "        1.3546802 ,  1.35437002,  1.3540605 ,  1.35375164,  1.35344344,\n",
       "        1.35313591,  1.35282902,  1.35252279,  1.35221721,  1.35191228,\n",
       "        1.35160799,  1.35130434,  1.35100133,  1.35069896,  1.35039723,\n",
       "        1.35009613,  1.34979566,  1.34949582,  1.3491966 ,  1.34889801,\n",
       "        1.34860003,  1.34830268,  1.34800594,  1.34770982,  1.3474143 ,\n",
       "        1.3471194 ,  1.3468251 ,  1.34653141,  1.34623832,  1.34594584,\n",
       "        1.34565395,  1.34536265,  1.34507195,  1.34478184,  1.34449232,\n",
       "        1.34420339,  1.34391504,  1.34362728,  1.3433401 ,  1.34305349,\n",
       "        1.34276746,  1.34248201,  1.34219713,  1.34191282,  1.34162907,\n",
       "        1.3413459 ,  1.34106328,  1.34078123,  1.34049974,  1.34021881,\n",
       "        1.33993843,  1.33965861,  1.33937934,  1.33910062,  1.33882245,\n",
       "        1.33854482,  1.33826774,  1.3379912 ,  1.3377152 ,  1.33743974,\n",
       "        1.33716482,  1.33689043,  1.33661658,  1.33634325,  1.33607045,\n",
       "        1.33579819,  1.33552644,  1.33525522,  1.33498453,  1.33471435,\n",
       "        1.33444469,  1.33417554,  1.33390692,  1.3336388 ,  1.33337119,\n",
       "        1.3331041 ,  1.33283751,  1.33257143,  1.33230585,  1.33204077,\n",
       "        1.3317762 ,  1.33151212,  1.33124854,  1.33098546,  1.33072286,\n",
       "        1.33046077,  1.33019916,  1.32993804,  1.32967741,  1.32941726,\n",
       "        1.3291576 ,  1.32889842,  1.32863972,  1.3283815 ,  1.32812375,\n",
       "        1.32786648,  1.32760969,  1.32735337,  1.32709752,  1.32684214,\n",
       "        1.32658723,  1.32633278,  1.3260788 ,  1.32582528,  1.32557222,\n",
       "        1.32531963,  1.32506749,  1.32481581,  1.32456458,  1.32431381,\n",
       "        1.3240635 ,  1.32381363,  1.32356421,  1.32331524,  1.32306672,\n",
       "        1.32281865,  1.32257101,  1.32232382,  1.32207708,  1.32183077,\n",
       "        1.3215849 ,  1.32133946,  1.32109446,  1.3208499 ,  1.32060577,\n",
       "        1.32036207,  1.3201188 ,  1.31987595,  1.31963354,  1.31939155,\n",
       "        1.31914998,  1.31890884,  1.31866812,  1.31842782,  1.31818794,\n",
       "        1.31794848,  1.31770943,  1.3174708 ,  1.31723258,  1.31699478,\n",
       "        1.31675738,  1.3165204 ,  1.31628382,  1.31604766,  1.31581189,\n",
       "        1.31557654,  1.31534158,  1.31510703,  1.31487288,  1.31463913,\n",
       "        1.31440578,  1.31417283,  1.31394027,  1.3137081 ,  1.31347633,\n",
       "        1.31324496,  1.31301397,  1.31278338,  1.31255317,  1.31232335,\n",
       "        1.31209392,  1.31186487,  1.31163621,  1.31140793,  1.31118003,\n",
       "        1.31095251,  1.31072537,  1.31049861,  1.31027223,  1.31004623,\n",
       "        1.30982059,  1.30959534,  1.30937045,  1.30914594,  1.3089218 ,\n",
       "        1.30869802,  1.30847462,  1.30825158,  1.30802891,  1.3078066 ,\n",
       "        1.30758466,  1.30736308,  1.30714186,  1.306921  ,  1.30670051,\n",
       "        1.30648037,  1.30626059,  1.30604116,  1.30582209,  1.30560338,\n",
       "        1.30538501,  1.305167  ,  1.30494935,  1.30473204,  1.30451508,\n",
       "        1.30429847,  1.3040822 ,  1.30386629,  1.30365072,  1.30343549,\n",
       "        1.3032206 ,  1.30300606,  1.30279186,  1.302578  ,  1.30236448,\n",
       "        1.30215129,  1.30193845,  1.30172594,  1.30151376,  1.30130192])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_event = 10\n",
    "sample = np.arange(0,800,1)\n",
    "\n",
    "min_event/(np.log(sample+1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1r = torch.zeros([1,1,100,100]) + 1\n",
    "h2r = torch.zeros([1,1,100,100]) + 2\n",
    "h3r = torch.zeros([1,1,100,100]) + 3\n",
    "\n",
    "h1c = torch.zeros([1,1,100,100]) + 0.1\n",
    "h2c = torch.zeros([1,1,100,100]) + 0.2\n",
    "h3c = torch.zeros([1,1,100,100]) + 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 100])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 100, 100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([h1c, h2c, h3c], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 100, 100])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([h1c, h2c], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "stack(tensors, dim=0, *, out=None) -> Tensor\n",
      "\n",
      "Concatenates a sequence of tensors along a new dimension.\n",
      "\n",
      "All tensors need to be of the same size.\n",
      "\n",
      "Arguments:\n",
      "    tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "    dim (int): dimension to insert. Has to be between 0 and the number\n",
      "        of dimensions of concatenated tensors (inclusive)\n",
      "\n",
      "Keyword args:\n",
      "    out (Tensor, optional): the output tensor.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1\n",
    "w = True\n",
    "\n",
    "if w == True:\n",
    "    x *= 5\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs = torch.zeros((1,16,16,16), dtype= torch.float64) # + torch.exp(torch.tensor(-100)\n",
    "# solutions:\n",
    "\n",
    "#hs = torch.randn((1,16,16,16), dtype= torch.float64) * torch.exp(torch.tensor(-100)) # one solution. Try this... This will give negative values, which is \"\"unecological\"\n",
    "\n",
    "#hs = F.relu(torch.randn((1,16,16,16), dtype= torch.float64) * torch.exp(torch.tensor(-100))) # one solution. This will give zeros which is numerically unstable\n",
    "\n",
    "hs = torch.abs(torch.randn((1,16,16,16), dtype= torch.float64) * torch.exp(torch.tensor(-100))) # one solution. Try this is likely most stable.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000e+00, 0.0000e+00, 9.3827e-44,  ..., 4.1876e-44,\n",
       "           0.0000e+00, 1.3102e-44],\n",
       "          [2.5093e-44, 3.9305e-44, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           4.4926e-44, 0.0000e+00],\n",
       "          [0.0000e+00, 2.0977e-44, 4.2679e-44,  ..., 0.0000e+00,\n",
       "           7.0584e-45, 5.9778e-44],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.6839e-44,\n",
       "           7.0992e-44, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           6.8960e-44, 6.8492e-44],\n",
       "          [5.0777e-44, 0.0000e+00, 1.0477e-44,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 8.9256e-46]],\n",
       "\n",
       "         [[2.9149e-44, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [2.0935e-44, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.1058e-44],\n",
       "          [0.0000e+00, 0.0000e+00, 6.8333e-44,  ..., 5.5678e-44,\n",
       "           0.0000e+00, 8.8894e-45],\n",
       "          ...,\n",
       "          [1.0733e-44, 0.0000e+00, 0.0000e+00,  ..., 4.7536e-45,\n",
       "           0.0000e+00, 2.8236e-44],\n",
       "          [1.9868e-44, 9.0955e-45, 0.0000e+00,  ..., 2.8720e-44,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [4.5724e-44, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.8950e-44]],\n",
       "\n",
       "         [[0.0000e+00, 2.8783e-45, 7.5458e-44,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.3155e-44, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           1.4636e-44, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.4559e-44,  ..., 8.2252e-45,\n",
       "           0.0000e+00, 1.6425e-44],\n",
       "          ...,\n",
       "          [7.4994e-45, 0.0000e+00, 0.0000e+00,  ..., 3.0406e-44,\n",
       "           4.4227e-45, 0.0000e+00],\n",
       "          [1.7573e-44, 0.0000e+00, 2.6260e-44,  ..., 0.0000e+00,\n",
       "           5.1727e-44, 0.0000e+00],\n",
       "          [0.0000e+00, 2.0246e-44, 4.5130e-45,  ..., 2.3352e-44,\n",
       "           0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 3.1868e-44,  ..., 0.0000e+00,\n",
       "           1.3896e-44, 5.0929e-45],\n",
       "          [1.7243e-44, 3.3316e-44, 0.0000e+00,  ..., 4.7847e-44,\n",
       "           0.0000e+00, 2.6258e-44],\n",
       "          [7.0622e-44, 1.1891e-44, 4.2404e-44,  ..., 5.1757e-45,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [2.9055e-44, 0.0000e+00, 0.0000e+00,  ..., 3.5811e-44,\n",
       "           3.0458e-44, 2.8571e-44],\n",
       "          [0.0000e+00, 5.7907e-44, 0.0000e+00,  ..., 6.4245e-44,\n",
       "           3.1663e-44, 1.9772e-44],\n",
       "          [0.0000e+00, 0.0000e+00, 4.6784e-44,  ..., 0.0000e+00,\n",
       "           9.5406e-45, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00, 3.9972e-44,  ..., 3.0514e-44,\n",
       "           0.0000e+00, 4.8461e-45],\n",
       "          [0.0000e+00, 3.5672e-44, 8.2317e-44,  ..., 2.8638e-44,\n",
       "           0.0000e+00, 3.1956e-44],\n",
       "          [2.7952e-44, 2.5748e-44, 0.0000e+00,  ..., 0.0000e+00,\n",
       "           2.5127e-44, 1.7907e-44],\n",
       "          ...,\n",
       "          [0.0000e+00, 0.0000e+00, 6.5180e-44,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 1.4455e-44],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.9805e-46,\n",
       "           0.0000e+00, 5.8330e-44],\n",
       "          [0.0000e+00, 4.4888e-44, 0.0000e+00,  ..., 4.7538e-44,\n",
       "           3.3657e-44, 0.0000e+00]],\n",
       "\n",
       "         [[3.3910e-44, 1.9137e-44, 1.3193e-44,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 2.8687e-44],\n",
       "          [0.0000e+00, 3.9388e-44, 0.0000e+00,  ..., 8.4712e-44,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.1455e-44,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          ...,\n",
       "          [7.7374e-44, 3.7661e-46, 2.2175e-44,  ..., 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00],\n",
       "          [1.7161e-44, 1.5333e-44, 0.0000e+00,  ..., 1.3482e-44,\n",
       "           1.5722e-44, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.3665e-44,  ..., 0.0000e+00,\n",
       "           2.1900e-44, 0.0000e+00]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "criterion_class = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            weight=None,\n",
    "            gamma=2.0,\n",
    "            reduction='mean'\n",
    "    ):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = torch.sigmoid(input_tensor)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        term = ((1.0 - prob) ** self.gamma) * log_prob\n",
    "        return F.nll_loss(term, target_tensor)\n",
    "        \n",
    "        #return F.nll_loss(term, target_tensor, weight=self.weight, reduction=self.reduction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss01(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, weight=None, size_average=True):\n",
    "        super(FocalLoss01, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.contiguous().view(input.size(0), input.size(1), -1)\n",
    "            input = input.transpose(1,2)\n",
    "            input = input.contiguous().view(-1, input.size(2)).squeeze()\n",
    "        if target.dim()==4:\n",
    "            target = target.contiguous().view(target.size(0), target.size(1), -1)\n",
    "            target = target.transpose(1,2)\n",
    "            target = target.contiguous().view(-1, target.size(2)).squeeze()\n",
    "        elif target.dim()==3:\n",
    "            target = target.view(-1)\n",
    "        else:\n",
    "            target = target.view(-1, 1)\n",
    "\n",
    "        # compute the negative likelyhood\n",
    "        weight = Variable(self.weight)\n",
    "        logpt = -F.cross_entropy(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = -((1-pt)**self.gamma) * logpt\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss02(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, weight=None, size_average=True):\n",
    "        super(FocalLoss02, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # if input.dim()>2:\n",
    "        #     input = input.contiguous().view(input.size(0), input.size(1), -1)\n",
    "        #     input = input.transpose(1,2)\n",
    "        #     input = input.contiguous().view(-1, input.size(2)).squeeze()\n",
    "        # if target.dim()==4:\n",
    "        #     target = target.contiguous().view(target.size(0), target.size(1), -1)\n",
    "        #     target = target.transpose(1,2)\n",
    "        #     target = target.contiguous().view(-1, target.size(2)).squeeze()\n",
    "        # elif target.dim()==3:\n",
    "        #     target = target.view(-1)\n",
    "        # else:\n",
    "        #     target = target.view(-1, 1)\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        # compute.unsqueeze(0)F.cross_entropy(input, target)\n",
    "        logpt = -F.cross_entropy(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = -((1-pt)**self.gamma) * logpt\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss03(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss03, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        # compute.unsqueeze(0)F.cross_entropy(input, target)\n",
    "        p = 1/(1+np.exp(-input))\n",
    "        loss = -( self.alpha*target + (1-self.alpha)*(1-target) ) * (( 1 - ( target*p + (1-target)*(1-p)) )**self.gamma) * ( target*np.log(p)+(1-target)*np.log(1-p) )\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss04(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss04, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        loss = -(target * np.log(input) + (1-target) * np.log(1-input)) #BCE\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss05(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss05, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * np.log(input) + (1-target) * np.log(1-input))\n",
    "        loss = -self.alpha * ((1-np.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST!!!\n",
    "\n",
    "class FocalLoss05(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss05, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * np.log(input) + (1-target) * np.log(1-input))\n",
    "        loss = -self.alpha * ((1-np.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossClass(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLossClass, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * torch.log(input) + (1-target) * torch.log(1-input))\n",
    "        loss = -self.alpha * ((1-torch.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "\n",
    "        #logpt = (self.alpha * target * torch.log(input) + (1-self.alpha) * (1-target) * torch.log(input))\n",
    "        #logpt = (self.alpha * target * torch.log(input) + (1-self.alpha) * (1-target) * torch.log(1-input))\n",
    "        \n",
    "        # could get more numerical stability be outputtin raw logits.... \n",
    "        \n",
    "        # a_pt = (target * self.alpha * input + (1-target) * 1-self.alpha  * 1-input)\n",
    "        # logpt = (target * torch.log(input) + (1-target) * torch.log(1-input))\n",
    "\n",
    "        # pos = self.alpha * ((1-input)**self.gamma) * torch.log(input)\n",
    "        # neg = (1-self.alpha) * ((input)**self.gamma) * torch.log(1-input)\n",
    "\n",
    "        # loss = -(target * pos + (1-target) * neg)\n",
    "\n",
    "        logpt = (target * torch.log(input) + (1-target) * torch.log(1-input))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        alphas = torch.tensor([self.alpha, (1-self.alpha)])\n",
    "        \n",
    "        pt = target * input  + (1-target) * (1-input)\n",
    "        \n",
    "        coef = (1-pt)**self.gamma\n",
    "        \n",
    "        loss = -coef * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # pos = -self.alpha * (1-input)**self.gamma * torch.log(input)\n",
    "        # neg = -(1-self.alpha) * input**self.gamma * torch.log(1-input)\n",
    "\n",
    "        # loss = (target * pos + (1-target) * neg)\n",
    "        \n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORKS!\n",
    "class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "        super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "\n",
    "        # pos = (-self.alpha * (1-input)**self.gamma * torch.log(input))\n",
    "        # neg = (-(1-self.alpha) * (1-1-input)**self.gamma *  torch.log(1-input))\n",
    "\n",
    "        pos = ( (1-input)**self.gamma * torch.log(input))\n",
    "        neg = ( (input)**self.gamma *  torch.log(1-input))\n",
    "\n",
    "        loss = -(pos * target + neg * (1-target))\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(p):\n",
    "    return (p * np.log(1/p)).sum()\n",
    "\n",
    "def cross_entropy(p, q):\n",
    "    return -(p * np.log(q)).sum() # same as (p * np.log(1/q)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_class = nn.BCELoss()\n",
    "\n",
    "x1 = torch.rand([ 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3078)\n",
      "tensor(0.3078)\n",
      "tensor(0.3078)\n",
      "tensor(0.3078)\n",
      "tensor(0.3078)\n"
     ]
    }
   ],
   "source": [
    "# criterion_focal01 = FocalLoss01(gamma=1)\n",
    "# criterion_focal02 = FocalLoss02(gamma=1, size_average=False)\n",
    "# criterion_focal03 = FocalLoss03(gamma=1, alpha = 1, size_average=True)\n",
    "\n",
    "criterion_focal04 = FocalLoss04(gamma=0)\n",
    "criterion_focal05 = FocalLoss05()\n",
    "\n",
    "criterion_focal06 = FocalLossClass()\n",
    "criterion_focal07 = BalancedFocalLossClass(gamma=0, alpha=0.5)\n",
    "\n",
    "# print(criterion_focal01(x1.unsqueeze(0), x1_b.unsqueeze(0)))\n",
    "# print(criterion_focal02(x1, x1_b))\n",
    "# print(criterion_focal03(x1, x1_b))\n",
    "\n",
    "\n",
    "print(criterion_focal04(x1, x1_b))\n",
    "\n",
    "print(criterion_focal05(x1, x1_b))\n",
    "\n",
    "print(criterion_focal06(x1, x1_b))\n",
    "\n",
    "print(criterion_focal07(x1, x1_b)) \n",
    "\n",
    "\n",
    "print(criterion_class(x1, x1_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_class01 = BalancedFocalLossClass(gamma=0.0, alpha=0.75)\n",
    "criterion_focal_class02 = BalancedFocalLossClass(gamma=2.0, alpha=0.25)\n",
    "criterion_focal_class03 = BalancedFocalLossClass(gamma=5.0, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focal, gamma = 0, alpha = 1 : \t 0.1558169275522232\n",
      "focal, gamma = 1, alpha = 1 : \t 0.019834911450743675\n",
      "focal, gamma = 2, alpha = 1 : \t -0.0006891923840157688\n"
     ]
    }
   ],
   "source": [
    "print(f'focal, gamma = 0, alpha = 1 : \\t {criterion_focal_class01(x1, x1_b)}')\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_class02(x1, x1_b)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_class03(x1, x1_b)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6931)"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.logsigmoid(torch.tensor(.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32)\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "RT = torch.rand([ 3 ,100, 100]) \n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9498)\n",
      "tensor(0.0358)\n"
     ]
    }
   ],
   "source": [
    "criterion = BalancedFocalLossClass(gamma=2, alpha=0.95)\n",
    "\n",
    "\n",
    "print(criterion(ZT, IT)) \n",
    "print(criterion(RT, IT)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss_reg, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        mse = (target - input)**2\n",
    "\n",
    "        loss = self.alpha * ((1-np.exp(mse))**self.gamma) * mse # for gamma = 0 and alpha = 1 we get the mse\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "\n",
    "x1 = torch.rand([ 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg01 = FocalLoss_reg(gamma=0)\n",
    "criterion_focal_reg02 = FocalLoss_reg(gamma=1)\n",
    "criterion_focal_reg03 = FocalLoss_reg(gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32)\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "OT = torch.zeros([ 3 ,100, 100]) + 1\n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: \t\t\t\t 0.3157702684402466\n",
      "focal, gamma = 0, alpha = 1 : \t 24.743696212768555\n",
      "focal, gamma = 1, alpha = 1 : \t -inf\n",
      "focal, gamma = 2, alpha = 1 : \t inf\n",
      "\n",
      "\n",
      "focal, gamma = 1, alpha = 1 : \t -0.33513134717941284\n",
      "focal, gamma = 2, alpha = 1 : \t -10.566515922546387\n",
      "focal, gamma = 3, alpha = 1 : \t 586.1552124023438\n"
     ]
    }
   ],
   "source": [
    "print(f'MSE: \\t\\t\\t\\t {criterion_reg(ZT, IT)}')\n",
    "print(f'focal, gamma = 0, alpha = 1 : \\t {criterion_focal_reg01(ZT, IT)}')\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_reg02(ZT, IT)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_reg03(ZT, IT)}')\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_reg01(OT, IT)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_reg02(OT, IT)}')\n",
    "print(f'focal, gamma = 3, alpha = 1 : \\t {criterion_focal_reg03(OT, IT)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(input, target):\n",
    "    loss = (target - input)**2\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(input, target):\n",
    "    se = target - input\n",
    "    lse = np.exp(se)  #torch.clamp(se, min = np.exp(-100)))\n",
    "    mlse = lse.mean()\n",
    "\n",
    "    return mlse\n",
    "\n",
    "    # return - np.log(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand([ 3 ,100, 100]) * 10\n",
    "\n",
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32) * noise\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "OT = (torch.zeros([ 3 ,100, 100]) + 1 ) * noise\n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.1620)\n",
      "tensor(0.1097)\n"
     ]
    }
   ],
   "source": [
    "print(MSE(ZT, IT))\n",
    "print(MSE(OT, IT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0006)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OT.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss_reg, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        #input = torch.clamp(input, min = np.exp(-100)) # could do this for no negatives???\n",
    "\n",
    "        error = target - input\n",
    "        exp_error = np.exp(error)  #torch.clamp(se, min = np.exp(-100)))\n",
    "        loss = exp_error.mean()\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShrinkageLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, a=10, c=0.2, size_average=True):\n",
    "        super(ShrinkageLoss, self).__init__()\n",
    "\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0) \n",
    "\n",
    "        l = torch.abs(target - input)     #F.l1_loss(input, target)\n",
    "\n",
    "        loss = (l**2)/(1 + torch.exp(self.a*(self.c-l)))\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg = ShrinkageLoss(a=10, c=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0083)\n",
      "tensor(1.0195)\n"
     ]
    }
   ],
   "source": [
    "criterion_focal_reg = ShrinkageLoss(a=1, c=12)\n",
    "\n",
    "print(criterion_focal_reg(ZT, IT))\n",
    "print(criterion_focal_reg(OT, IT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7491.8901)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shannon_entropy(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4593.0488)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4593.0488)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(223.4796)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy( x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "This criterion computes the cross entropy loss between input logits and target.\n",
      "\n",
      "See :class:`~torch.nn.CrossEntropyLoss` for details.\n",
      "\n",
      "Args:\n",
      "    input (Tensor) : Predicted unnormalized logits;\n",
      "        see Shape section below for supported shapes.\n",
      "    target (Tensor) : Ground truth class indices or class probabilities;\n",
      "        see Shape section below for supported shapes.\n",
      "    weight (Tensor, optional): a manual rescaling weight given to each\n",
      "        class. If given, has to be a Tensor of size `C`\n",
      "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "        the losses are averaged over each loss element in the batch. Note that for\n",
      "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "        when reduce is ``False``. Default: ``True``\n",
      "    ignore_index (int, optional): Specifies a target value that is ignored\n",
      "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "        ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "        :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "        Default: -100\n",
      "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "        losses are averaged or summed over observations for each minibatch depending\n",
      "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "    reduction (str, optional): Specifies the reduction to apply to the output:\n",
      "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "        ``'mean'``: the sum of the output will be divided by the number of\n",
      "        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "        become a mixture of the original ground truth and a uniform distribution as described in\n",
      "        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "\n",
      "Shape:\n",
      "    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "      in the case of `K`-dimensional loss.\n",
      "    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.\n",
      "      If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.\n",
      "\n",
      "    where:\n",
      "\n",
      "    .. math::\n",
      "        \\begin{aligned}\n",
      "            C ={} & \\text{number of classes} \\\\\n",
      "            N ={} & \\text{batch size} \\\\\n",
      "        \\end{aligned}\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> # Example of target with class indices\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randint(5, (3,), dtype=torch.int64)\n",
      "    >>> loss = F.cross_entropy(input, target)\n",
      "    >>> loss.backward()\n",
      "    >>>\n",
      "    >>> # Example of target with class probabilities\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "    >>> loss = F.cross_entropy(input, target)\n",
      "    >>> loss.backward()\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/nn/functional.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "F.cross_entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1531)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(x1_b * np.log(x1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1531)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1_b * (np.log(1/x1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0988)\n",
      "tensor(0.3070)\n"
     ]
    }
   ],
   "source": [
    "print(criterion_focal02(x1, x1_b))\n",
    "print(criterion_class(x1, x1_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 3\n",
    "\n",
    "if t == 1 or t == 0:\n",
    "    print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSLELoss(\n",
       "  (mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgoairb: RMSLELoss(\n",
      "  (mse): MSELoss()\n",
      ")\n",
      "..................\n"
     ]
    }
   ],
   "source": [
    "cr = RMSLELoss()\n",
    "print(f'sgoairb: {cr}\\n..................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([3,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal = FocalLoss2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FocalLoss2d()\n"
     ]
    }
   ],
   "source": [
    "print(criterion_focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4365)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_focal(x1.unsqueeze(0), x1_b.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1051)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "sigmoid_focal_loss(x1, x1_b, reduction= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2466)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])#.type(torch.LongTensor)\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "criterion_focal(x1.reshape(-1), x1_b.reshape(-1).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3178)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "#x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x2 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "x3 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x4 = torch.randn([1, 3 ,100, 100]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9961)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x1_ = x1.reshape(-1)\n",
    "# x2_ = x2.reshape(-1)\n",
    "\n",
    "# mask = x1_ > 0\n",
    "\n",
    "# x1_[mask].shape\n",
    "\n",
    "# criterion_reg(x1_, x2_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(losses_list) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    x1_ = x1[:,i,:,:].reshape(-1)\n",
    "    x2_ = x2[:,i,:,:].reshape(-1)\n",
    "    mask = (x3[:,i,:,:].reshape(-1) > 0.0001) | (x4[:,i,:,:].reshape(-1) > 0.0001)\n",
    "\n",
    "    losses_list.append(criterion_reg(x1_[mask], x2_[mask]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(2.0036), tensor(1.9821), tensor(1.9411)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    losses_list.append(criterion_class(t1_pred_class[:,i,:,:], t1_binary[:,i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    losses_list.append(torch.tensor(1.0))\n",
    "\n",
    "for i in range(3):\n",
    "    losses_list.append(torch.tensor(2.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.stack(losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[-3:].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(2.)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 32\n",
    "D = 16 \n",
    "\n",
    "\n",
    "X = torch.rand(1, 3, D, D)\n",
    "H = torch.rand(1, hidden_channels, D, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m H\u001b[39m+\u001b[39;49mX\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "H+X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c2 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c3 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c4 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c5 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c6 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.sigmoid(c1(X) + c2(H))\n",
    "\n",
    "R = torch.sigmoid(c3(X) + c4(H))\n",
    "\n",
    "H_tilde = torch.tanh(c5(X) + c6(torch.mul(R,H)))\n",
    "\n",
    "H = torch.mul(torch.mul(Z,H) + (1 - Z), H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 16, 16])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 48, 3, 180, 180])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = np.zeros([1,48,3,180,180])\n",
    "tens  =torch.tensor(vol)\n",
    "\n",
    "torch.stack((tens,tens)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.zeros([1,48,3,180,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[:,:,0,:,:] = 1\n",
    "vol[:,:,1,:,:] = 2\n",
    "vol[:,:,2,:,:] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 3, 180, 180)\n",
      "1.0\n",
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(vol.shape)\n",
    "print(vol[:,:,0,:,:].mean())\n",
    "print(vol[:,:,1,:,:].mean())\n",
    "print(vol[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 144, 180, 180)\n"
     ]
    }
   ],
   "source": [
    "N = vol.shape[0] # batch size. Always 1\n",
    "C = vol.shape[1] # months\n",
    "D = vol.shape[2] # features\n",
    "H = vol.shape[3] # height\n",
    "W = vol.shape[4] # width\n",
    "\n",
    "vol2 = vol.reshape(N, C*D, H, W)\n",
    "print(vol2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = transforms.Compose([transforms.RandomRotation((0,360)), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])\n",
    "transformer = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation (can be turned of for final experiments)        \n",
    "vol2 = transformer(torch.tensor(vol2)) # rotations and flips # skip for now... '''''''''''''''''''''''''''''''''''''''''''''''''''''' bug only take 4 dims.. could just squezze the batrhc dom and then give it again afterwards?#train_tensor = train_tensor.reshape(N, C, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48, 3, 180, 180])\n",
      "tensor(1., dtype=torch.float64)\n",
      "tensor(2., dtype=torch.float64)\n",
      "tensor(3., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "vol3 = vol2.reshape(N,C,D,H,W)\n",
    "print(vol3.shape)\n",
    "print(vol3[:,:,0,:,:].mean())\n",
    "print(vol3[:,:,1,:,:].mean())\n",
    "print(vol3[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vol3 == vol).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e07914b3d36b3c0ae84e5e97633abec307a3dfe696e94a6042eabf44e48503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
