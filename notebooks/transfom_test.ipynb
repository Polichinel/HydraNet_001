{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posterior(model, views_vol, config, device): \n",
    "\n",
    "    \"\"\"\n",
    "    Samples from the posterior distribution of Hydranet.\n",
    "\n",
    "    Args:\n",
    "    - model: HydraNet\n",
    "    - views_vol (torch.Tensor): Input views data.\n",
    "    - config: Configuration file\n",
    "    - device: Device for computations.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (posterior_magnitudes, posterior_probabilities, out_of_sample_data)\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Drawing {config.test_samples} posterior samples...')\n",
    "\n",
    "    # perhaps not on GPU? \n",
    "    test_tensor = get_test_tensor(views_vol, config, device) # better cal thiis evel tensor\n",
    "    out_of_sample_vol = test_tensor[:,-config.time_steps:,:,:,:].cpu().numpy() # From the test tensor get the out-of-sample time_steps. \n",
    "\n",
    "    posterior_list = []\n",
    "    posterior_list_class = []\n",
    "\n",
    "    for i in range(config.test_samples): # number of posterior samples to draw - just set config.test_samples, no? \n",
    "        \n",
    "        pred_np_list, pred_class_np_list = test(model, test_tensor, config.time_steps, config, device) # Returns two lists of numpy arrays (shape 3/180/180). One list of the predicted magnitudes and one list of the predicted probabilities.\n",
    "        posterior_list.append(pred_np_list)\n",
    "        posterior_list_class.append(pred_class_np_list)\n",
    "\n",
    "        #if i % 10 == 0: # print steps 10\n",
    "        print(f'Posterior sample: {i}/{config.test_samples}', end = '\\r')\n",
    "\n",
    "    return posterior_list, posterior_list_class, out_of_sample_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Dump 1\n",
    "    if config.sweep == False:\n",
    "        dump_location = '/home/projects/ku_00017/data/generated/conflictNet/'\n",
    "        posterior_dict = {'posterior_list' : posterior_list, 'posterior_list_class': posterior_list_class, 'out_of_sample_vol' : out_of_sample_vol}\n",
    "        with open(f'{dump_location}posterior_dict_{config.time_steps}_{config.run_type}.pkl', 'wb') as file:\n",
    "            pickle.dump(posterior_dict, file)\n",
    "\n",
    "        print(\"Posterior pickle dumped!\")\n",
    "\n",
    "    else:\n",
    "        print('Running sweep. no posterior pickle dumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "tree_d_tensor01 = torch.tensor([[[1, 2, 3]], [[4, 5, 6]]])\n",
    "tree_d_tensor02 = torch.tensor([[[7, 8, 9]], [[10, 11, 12]]])\n",
    "tree_d_tensor03 = torch.tensor([[[13, 14, 15]], [[16, 17, 18]]])\n",
    "\n",
    "tree_d_tensor = torch.cat((tree_d_tensor01, tree_d_tensor02, tree_d_tensor03), dim=1)\n",
    "\n",
    "print(tree_d_tensor.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "two_d_tensor01 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "two_d_tensor02 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "two_d_tensor03 = torch.tensor([[13, 14, 15], [16, 17, 18]])\n",
    "\n",
    "print(torch.cat((two_d_tensor01, two_d_tensor02, two_d_tensor03), dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_channels = 32\n",
    "\n",
    "\n",
    "hidden_channels_split = int(hidden_channels/8)\n",
    "\n",
    "hidden_channels_split * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# https://d2l.ai/chapter_recurrent-modern/gru.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"/home/simon/Documents/scripts/conflictNet/src/utils\")\n",
    "from warmup_decay_lr_scheduler import WarmupDecayLearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 32])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, 32, 32, 32), dtype=torch.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros((1, 32, 32, 32), dtype=torch.float32)\n",
    "\n",
    "h[:, :4, :, :] = 1\n",
    "h[:, 4:8, :, :] = 2\n",
    "h[:, 8:12, :, :] = 3\n",
    "h[:, 12:16, :, :] = 4\n",
    "h[:, 16:20, :, :] = 5\n",
    "h[:, 20:24, :, :] = 6  \n",
    "h[:, 24:28, :, :] = 7 \n",
    "h[:, 28:32, :, :] = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(4.)\n",
      "tensor(5.)\n",
      "tensor(6.)\n",
      "tensor(7.)\n",
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "split_8_ways = int(h.shape[1] / 8) \n",
    "\n",
    "hs1, hs2, hs3, hs4, hl1, hl2, hl3, hl4 = torch.split(h, split_8_ways, dim=1) \n",
    "new_h = torch.cat([hs1, hs2, hs3, hs4, hl1, hl2, hl3, hl4], dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(new_h[:, :4, :, :].mean())\n",
    "print(new_h[:, 4:8, :, :].mean())\n",
    "print(new_h[:, 8:12, :, :].mean())\n",
    "print(new_h[:, 12:16, :, :].mean())\n",
    "print(new_h[:, 16:20, :, :].mean())\n",
    "print(new_h[:, 20:24, :, :].mean())\n",
    "print(new_h[:, 24:28, :, :].mean())\n",
    "print(new_h[:, 28:32, :, :].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          ...,\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.]],\n",
       "\n",
       "         [[4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          ...,\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.]],\n",
       "\n",
       "         [[4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          ...,\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.]],\n",
       "\n",
       "         [[4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          ...,\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "          [4., 4., 4.,  ..., 4., 4., 4.]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros((1, 32, 32, 32), dtype=torch.float32)\n",
    "\n",
    "h[:, :8, :, :] += 1  \n",
    "h[:, 8:16, :, :] += 2 \n",
    "h[:, 16:24, :, :] += 3\n",
    "h[:, 24:, :, :] += 4\n",
    "\n",
    "h_frozen = h.clone()\n",
    "h_new = h.clone() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(-4.)\n"
     ]
    }
   ],
   "source": [
    "split_four_ways = int(h_frozen.shape[1] / 4) \n",
    "\n",
    "hs_1_frozen, hs_2_frozen, hl_1_frozen, hl_2_frozen = torch.split(h_frozen, split_four_ways, dim=1)\n",
    "hs_1_new, hs_2_new, hl_1_new, hl_2_new = torch.split(h_new, split_four_ways, dim=1) \n",
    "\n",
    "pairs = [(hs_1_frozen, hs_1_new), (hs_2_frozen, hs_2_new), (hl_1_frozen, hl_1_new), (hl_2_frozen, hl_2_new)]\n",
    "\n",
    "h_mix = torch.cat([pair[0] if torch.rand(1) < 0.5 else pair[1] for pair in pairs], dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "print(h_mix[:, :8, :, :].mean())\n",
    "print(h_mix[:, 8:16, :, :].mean())\n",
    "print(h_mix[:, 16:24, :, :].mean())\n",
    "print(h_mix[:, 24:, :, :].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(-4.)\n"
     ]
    }
   ],
   "source": [
    "print(h_mix[:, :8, :, :].mean())\n",
    "print(h_mix[:, 8:16, :, :].mean())\n",
    "print(h_mix[:, 16:24, :, :].mean())\n",
    "print(h_mix[:, 24:, :, :].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          ...,\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.]],\n",
       "\n",
       "         [[-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          ...,\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.]],\n",
       "\n",
       "         [[-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          ...,\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          ...,\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.]],\n",
       "\n",
       "         [[-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          ...,\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.]],\n",
       "\n",
       "         [[-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          ...,\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.],\n",
       "          [-4., -4., -4.,  ..., -4., -4., -4.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_mix[:, 24:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tensors = torch.cat(selected_tensors, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 32])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_hs_hl = int(h.shape[1] / 4)  # Half of the second dimension, which is channels\n",
    "\n",
    "# Split the tensor along dimension 1 into 4 parts\n",
    "hs_1, hs_2, hl_1, hl_2 = torch.split(h, split_hs_hl, dim=1)\n",
    "\n",
    "# The result will be a tuple of four tensors\n",
    "# hs_1, hs_2, hl_1, hl_2 = split_tensors_hs_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 32, 32])\n",
      "torch.Size([1, 8, 32, 32])\n",
      "torch.Size([1, 8, 32, 32])\n",
      "torch.Size([1, 8, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(hs_1.shape)\n",
    "print(hs_2.shape)\n",
    "print(hl_1.shape)\n",
    "print(hl_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(hs_1.mean())\n",
    "print(hs_2.mean())\n",
    "print(hl_1.mean())\n",
    "print(hl_2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_hs_hl = int(h.shape[1]/2) # half of the second dimension wich is channels\n",
    "\n",
    "# Split the tensor along dimension 1\n",
    "split_tensors_hs_hl = torch.split(h, split_hs_hl, dim=1)\n",
    "\n",
    "# The result will be a tuple of two tensors\n",
    "hs, hl = split_tensors_hs_hl\n",
    "\n",
    "# Second split to get the two tensors that make up hs and hl\n",
    "split_1_2 = int(split_hs_hl/2) # half of the second dimension wich is channels\n",
    "\n",
    "split_tensors_hs1_hs2 = torch.split(hs, split_1_2, dim=1)\n",
    "\n",
    "split_tensors_hl1_hl2 = torch.split(hl, split_1_2, dim=1)\n",
    "\n",
    "hs_1, hs_2 = split_tensors_hs1_hs2\n",
    "hl_1, hl_2 = split_tensors_hl1_hl2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have h_a and h_b tensors\n",
    "\n",
    "# Create lists of tensors from h_a and h_b\n",
    "tensors_a = [hs_1a, hs_2a, hl_1a, hl_2a]\n",
    "tensors_b = [hs_1b, hs_2b, hl_1b, hl_2b]\n",
    "\n",
    "# Shuffle the order of selection\n",
    "random.shuffle(tensors_a)\n",
    "random.shuffle(tensors_b)\n",
    "\n",
    "# Combine tensors from a and b\n",
    "result_tensors = [tensors_a.pop() if random.choice([True, False]) else tensors_b.pop() for _ in range(4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 32, 32])\n",
      "torch.Size([1, 8, 32, 32])\n",
      "torch.Size([1, 8, 32, 32])\n",
      "torch.Size([1, 8, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(hs_1.shape)\n",
    "print(hs_2.shape)\n",
    "print(hl_1.shape)\n",
    "print(hl_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(h_tt.shape[1]/2) # split h_tt into hs_tt and hl_tt and save hl_tt as the forzen cell state/long term memory. Call it hl_frozen. Half of the second dimension which is channels.\n",
    "_, hl_frozen = torch.split(h_tt, split, dim=1)\n",
    "t1_pred, t1_pred_class, h_tt = model(t0, h_tt) \n",
    "hs, _ = torch.split(h_tt, split, dim=1) # Again split the h_tt into hs_tt and hl_tt. But discard the hl_tt\n",
    "h_tt = torch.cat((hs, hl_frozen), dim=1) # Concatenate the frozen cell state/long term memory (hl_frozen) with the new hidden state/short term memory. this is the new h_tt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j\n",
      "j\n",
      "j\n",
      "e\n",
      "a\n",
      "e\n",
      "j\n",
      "e\n",
      "e\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    print(['j','a','e'][np.random.choice(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terning(max, antal, exprmnt):\n",
    "\n",
    "    \"\"\"\n",
    "    Max er den højeste værdi terningen kan vise, dvs. ternings antal sider.\n",
    "    Antal er antallet af terninger der kastes.\n",
    "    Exprmnt er antallet af eksperimenter der udføres.\n",
    "    \"\"\"\n",
    "\n",
    "    result = np.random.randint(1, max+1, (antal, exprmnt))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mterning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexprmnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Max er den højeste værdi terningen kan vise, dvs. ternings antal sider.\n",
      "Antal er antallet af terninger der kastes.\n",
      "exprmnt er antallet af eksperimenter der udføres.\n",
      "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_51386/728988540.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "terning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 2 5 4 3 3 4 4 3 2 2 4 5 4 3 3 4 5 4 1 5 5 2 4 5 3 3 3 4 2 4 4 5 2 3\n",
      "  5 1 3 1 1 5 1 1 1 4 4 3 4 5 2 5 4 2 1 1 4 3 4 3 4 1 2 4 3 4 1 5 4 5 1 2\n",
      "  2 4 3 1 2 4 4 5 2 2 5 3 4 1 1 2 4 4 3 2 4 3 4 5 5 4 1 4]\n",
      " [2 5 4 3 3 5 1 1 5 2 2 5 4 5 3 4 5 2 4 1 3 4 3 2 3 5 5 1 1 2 4 1 5 5 3 4\n",
      "  1 3 3 2 2 2 3 4 1 2 1 3 5 3 4 1 1 4 5 1 3 5 1 1 5 5 3 5 2 3 2 1 3 2 5 1\n",
      "  5 2 4 2 4 2 2 4 5 2 1 2 1 4 5 4 2 5 4 1 4 5 5 1 5 4 2 2]]\n"
     ]
    }
   ],
   "source": [
    "to_d_6_100 =  terning(6, 2, 100)\n",
    "print(to_d_6_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  7,  6,  8,  7,  8,  4,  5,  9,  5,  4,  7,  8, 10,  7,  7,  8,\n",
       "        6,  9,  5,  4,  9,  8,  4,  7, 10,  8,  4,  4,  6,  6,  5,  9, 10,\n",
       "        5,  7,  6,  4,  6,  3,  3,  7,  4,  5,  2,  6,  5,  6,  9,  8,  6,\n",
       "        6,  5,  6,  6,  2,  7,  8,  5,  4,  9,  6,  5,  9,  5,  7,  3,  6,\n",
       "        7,  7,  6,  3,  7,  6,  7,  3,  6,  6,  6,  9,  7,  4,  6,  5,  5,\n",
       "        5,  6,  6,  6,  9,  7,  3,  8,  8,  9,  6, 10,  8,  3,  6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmg = to_d_6_100.sum(0)\n",
    "dmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dmg, bins=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_vol = torch.zeros((300, 256, 256, 4), dtype=torch.float32) #  [N, C, D, H, W]\n",
    "\n",
    "full_vol = torch.randn((300, 256, 256, 4), dtype=torch.float32)**2 #  [N, C, D, H, W]\n",
    "\n",
    "\n",
    "full_vol[:, :, :, 0] += 99  \n",
    "full_vol[:, :, :, 1] += 1 \n",
    "full_vol[:, :, :, 2] += 2\n",
    "full_vol[:, :, :, 3] += 3\n",
    "\n",
    "full_vol = torch.log(full_vol+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.6071, 1.9131, 2.0007, 1.3871],\n",
       "          [4.6168, 0.8975, 1.2306, 1.4198],\n",
       "          [4.6066, 0.9201, 1.2958, 1.4596],\n",
       "          ...,\n",
       "          [4.6072, 0.9943, 1.0989, 1.3930],\n",
       "          [4.6068, 1.0841, 1.2980, 1.4747],\n",
       "          [4.6066, 0.9120, 1.1755, 1.5574]],\n",
       "\n",
       "         [[4.6068, 1.8559, 1.1686, 1.4734],\n",
       "          [4.6082, 1.0379, 1.5292, 1.5191],\n",
       "          [4.6067, 0.7474, 1.1406, 1.4072],\n",
       "          ...,\n",
       "          [4.6149, 1.2681, 1.1181, 1.4900],\n",
       "          [4.6069, 0.8128, 1.2314, 1.5005],\n",
       "          [4.6063, 1.0456, 1.1055, 1.3885]],\n",
       "\n",
       "         [[4.6300, 0.9509, 1.1051, 1.5466],\n",
       "          [4.6055, 0.7621, 1.2789, 1.6862],\n",
       "          [4.6052, 1.9078, 1.0990, 1.4118],\n",
       "          ...,\n",
       "          [4.6409, 1.1312, 1.4496, 1.3982],\n",
       "          [4.6087, 0.7045, 1.1326, 1.7147],\n",
       "          [4.6086, 1.1747, 2.1570, 1.5328]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.6142, 0.6940, 1.1042, 1.6339],\n",
       "          [4.6281, 0.6940, 1.3758, 1.4216],\n",
       "          [4.6052, 1.1891, 1.2322, 1.3966],\n",
       "          ...,\n",
       "          [4.6052, 0.7537, 1.1598, 1.5714],\n",
       "          [4.6104, 0.7213, 1.1464, 1.7014],\n",
       "          [4.6052, 0.7110, 1.1525, 1.7505]],\n",
       "\n",
       "         [[4.6052, 0.9281, 1.1760, 1.6606],\n",
       "          [4.6847, 0.9976, 1.1164, 1.4100],\n",
       "          [4.6080, 0.7582, 1.2846, 1.3867],\n",
       "          ...,\n",
       "          [4.6098, 0.7683, 1.1029, 1.8130],\n",
       "          [4.6102, 0.7110, 1.1513, 1.3933],\n",
       "          [4.6267, 0.9456, 1.9163, 1.4245]],\n",
       "\n",
       "         [[4.6369, 0.6970, 1.4429, 1.3867],\n",
       "          [4.6221, 0.7333, 1.1447, 1.6854],\n",
       "          [4.6086, 1.3417, 1.6993, 1.3978],\n",
       "          ...,\n",
       "          [4.6052, 0.7665, 1.2615, 1.3915],\n",
       "          [4.6166, 0.8252, 1.1274, 1.4174],\n",
       "          [4.6453, 0.6951, 1.6576, 1.6247]]],\n",
       "\n",
       "\n",
       "        [[[4.6057, 0.7003, 1.1266, 1.3864],\n",
       "          [4.6059, 0.7209, 1.2545, 1.4008],\n",
       "          [4.6216, 0.7590, 1.1639, 1.4873],\n",
       "          ...,\n",
       "          [4.6105, 2.2103, 1.4076, 1.6521],\n",
       "          [4.6056, 0.8214, 1.1253, 2.1372],\n",
       "          [4.6084, 0.7334, 1.1015, 1.7346]],\n",
       "\n",
       "         [[4.6446, 0.7061, 1.4277, 1.4464],\n",
       "          [4.6086, 0.9400, 1.4408, 1.5916],\n",
       "          [4.6109, 0.9188, 1.4271, 1.3882],\n",
       "          ...,\n",
       "          [4.6186, 1.5317, 1.5552, 2.0367],\n",
       "          [4.6142, 0.8504, 1.9987, 1.7032],\n",
       "          [4.6090, 0.9292, 1.8135, 1.4633]],\n",
       "\n",
       "         [[4.6115, 1.6767, 1.5107, 1.8817],\n",
       "          [4.6364, 0.6988, 1.1038, 1.7210],\n",
       "          [4.6058, 1.6206, 1.2592, 1.8367],\n",
       "          ...,\n",
       "          [4.6052, 0.6943, 1.2953, 1.7694],\n",
       "          [4.6108, 1.5435, 1.0988, 1.6550],\n",
       "          [4.6053, 0.8378, 1.2926, 1.3870]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.6151, 0.6933, 2.0485, 1.4204],\n",
       "          [4.6071, 0.7033, 1.1048, 1.4624],\n",
       "          [4.6488, 0.8850, 1.1335, 1.3971],\n",
       "          ...,\n",
       "          [4.6371, 1.0047, 1.1036, 1.7959],\n",
       "          [4.6178, 1.2559, 1.5643, 1.3987],\n",
       "          [4.6088, 0.7060, 1.2723, 2.0306]],\n",
       "\n",
       "         [[4.6101, 1.2886, 1.1040, 1.8857],\n",
       "          [4.6055, 0.7088, 1.2244, 1.4958],\n",
       "          [4.6132, 1.3770, 1.0987, 1.5732],\n",
       "          ...,\n",
       "          [4.7077, 0.7192, 1.1206, 1.4093],\n",
       "          [4.6067, 0.8469, 1.1261, 1.7154],\n",
       "          [4.6156, 0.7353, 1.1042, 1.4363]],\n",
       "\n",
       "         [[4.6052, 0.7343, 1.0987, 1.6426],\n",
       "          [4.6066, 1.1587, 1.0986, 1.5045],\n",
       "          [4.6085, 1.5294, 1.2059, 1.7095],\n",
       "          ...,\n",
       "          [4.6054, 1.3630, 1.3701, 1.3875],\n",
       "          [4.6281, 0.9408, 1.1791, 1.4223],\n",
       "          [4.6067, 0.7478, 1.3606, 1.4117]]],\n",
       "\n",
       "\n",
       "        [[[4.6078, 1.0406, 1.3810, 1.7478],\n",
       "          [4.6304, 0.8793, 1.1773, 1.4858],\n",
       "          [4.6052, 0.7055, 1.5564, 1.4705],\n",
       "          ...,\n",
       "          [4.6068, 0.9625, 1.8020, 1.8884],\n",
       "          [4.6316, 0.8742, 1.0999, 1.3863],\n",
       "          [4.6562, 0.9093, 2.2613, 1.4096]],\n",
       "\n",
       "         [[4.6063, 0.9977, 1.6686, 1.3910],\n",
       "          [4.6062, 1.1390, 1.3474, 1.3917],\n",
       "          [4.6174, 0.7489, 1.1422, 1.3991],\n",
       "          ...,\n",
       "          [4.6149, 1.0537, 1.2933, 1.7587],\n",
       "          [4.6084, 0.9164, 1.2767, 1.6001],\n",
       "          [4.6324, 1.1181, 1.0992, 1.4039]],\n",
       "\n",
       "         [[4.6053, 1.6408, 1.3472, 1.4828],\n",
       "          [4.6172, 0.8554, 1.3331, 1.3863],\n",
       "          [4.6068, 0.8179, 1.3037, 1.4911],\n",
       "          ...,\n",
       "          [4.6127, 1.0372, 1.0988, 1.3866],\n",
       "          [4.6055, 1.7392, 1.1032, 1.4723],\n",
       "          [4.6062, 0.9495, 1.2268, 1.4044]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.6061, 0.7547, 1.1343, 1.5366],\n",
       "          [4.6052, 0.7516, 1.7532, 1.4482],\n",
       "          [4.6068, 1.1065, 2.0372, 1.7506],\n",
       "          ...,\n",
       "          [4.6052, 0.7137, 1.5045, 1.4244],\n",
       "          [4.6254, 0.6997, 1.1000, 1.6965],\n",
       "          [4.6055, 0.7322, 1.4362, 1.7615]],\n",
       "\n",
       "         [[4.6061, 0.8174, 1.6755, 1.4908],\n",
       "          [4.6207, 0.7573, 1.2910, 1.3930],\n",
       "          [4.6168, 1.1004, 1.0986, 2.0227],\n",
       "          ...,\n",
       "          [4.6270, 1.0710, 1.2238, 1.8360],\n",
       "          [4.6225, 0.7151, 1.4516, 1.6658],\n",
       "          [4.6092, 0.7722, 1.0986, 2.0688]],\n",
       "\n",
       "         [[4.6054, 0.6940, 1.2103, 2.1675],\n",
       "          [4.6427, 0.7490, 1.1624, 1.9533],\n",
       "          [4.6068, 0.7315, 1.1341, 1.3866],\n",
       "          ...,\n",
       "          [4.6066, 0.7807, 1.1015, 1.4411],\n",
       "          [4.6139, 1.1009, 1.2274, 1.7526],\n",
       "          [4.6054, 0.9056, 1.7226, 1.3892]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[4.6057, 1.1050, 1.3194, 1.5908],\n",
       "          [4.6117, 0.8336, 1.2674, 1.4118],\n",
       "          [4.6064, 1.0026, 1.2076, 1.5489],\n",
       "          ...,\n",
       "          [4.6059, 0.7148, 1.1281, 1.8545],\n",
       "          [4.6083, 0.8254, 1.1223, 1.4464],\n",
       "          [4.6269, 0.6937, 1.6467, 2.0922]],\n",
       "\n",
       "         [[4.6151, 0.7019, 1.2706, 1.5033],\n",
       "          [4.6056, 1.2568, 1.1000, 1.4189],\n",
       "          [4.6059, 1.4791, 1.3856, 1.5606],\n",
       "          ...,\n",
       "          [4.6178, 1.1191, 1.5739, 1.6968],\n",
       "          [4.6152, 1.1564, 1.1286, 1.5537],\n",
       "          [4.6058, 1.1525, 1.1056, 1.5437]],\n",
       "\n",
       "         [[4.6056, 1.2099, 1.9843, 1.4505],\n",
       "          [4.6138, 0.7034, 1.3686, 1.5874],\n",
       "          [4.6107, 1.1812, 1.1911, 1.4820],\n",
       "          ...,\n",
       "          [4.6084, 0.7039, 1.5512, 1.4519],\n",
       "          [4.6195, 1.6014, 1.2710, 1.8607],\n",
       "          [4.6052, 0.7505, 1.1737, 1.9270]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.6069, 0.8604, 1.7269, 1.5000],\n",
       "          [4.6304, 0.9148, 1.1082, 1.4122],\n",
       "          [4.6060, 0.7871, 2.1465, 1.6505],\n",
       "          ...,\n",
       "          [4.6166, 1.9572, 1.1717, 1.4796],\n",
       "          [4.6052, 1.3952, 1.1684, 1.8562],\n",
       "          [4.6134, 0.7351, 1.1098, 1.6845]],\n",
       "\n",
       "         [[4.6055, 0.7066, 2.2263, 1.4800],\n",
       "          [4.6442, 0.9111, 1.2325, 1.4104],\n",
       "          [4.6315, 2.0964, 1.3281, 1.4086],\n",
       "          ...,\n",
       "          [4.6054, 1.2051, 1.1646, 1.5633],\n",
       "          [4.6067, 1.5383, 1.0998, 2.2020],\n",
       "          [4.6160, 0.7399, 1.1693, 1.7650]],\n",
       "\n",
       "         [[4.6052, 1.5023, 1.4457, 1.6811],\n",
       "          [4.6118, 1.6475, 1.1519, 1.4012],\n",
       "          [4.6189, 0.7804, 1.1060, 1.8508],\n",
       "          ...,\n",
       "          [4.6178, 1.0336, 1.8535, 1.7945],\n",
       "          [4.6054, 0.7177, 2.1957, 1.6902],\n",
       "          [4.6052, 0.9557, 1.3168, 1.3865]]],\n",
       "\n",
       "\n",
       "        [[[4.6207, 0.7096, 1.1013, 1.4217],\n",
       "          [4.6068, 1.1670, 1.1418, 1.7309],\n",
       "          [4.6501, 0.6953, 1.9083, 1.4656],\n",
       "          ...,\n",
       "          [4.6131, 0.9438, 1.1173, 1.4331],\n",
       "          [4.6101, 1.1883, 1.1194, 1.6494],\n",
       "          [4.6058, 0.9728, 1.2701, 1.6876]],\n",
       "\n",
       "         [[4.6081, 0.7140, 1.5343, 1.4006],\n",
       "          [4.6072, 0.9479, 1.0990, 1.4197],\n",
       "          [4.6052, 0.8350, 1.1238, 1.6448],\n",
       "          ...,\n",
       "          [4.6098, 0.6946, 1.1516, 1.4149],\n",
       "          [4.6123, 1.5703, 1.6092, 2.0001],\n",
       "          [4.6065, 1.4011, 1.4868, 1.9490]],\n",
       "\n",
       "         [[4.6062, 1.3617, 1.1285, 1.8549],\n",
       "          [4.6054, 0.7740, 1.2204, 1.3891],\n",
       "          [4.6139, 0.8501, 1.4005, 1.5466],\n",
       "          ...,\n",
       "          [4.6055, 0.7129, 1.1711, 1.3912],\n",
       "          [4.6193, 0.7997, 1.2700, 1.3920],\n",
       "          [4.6531, 0.8257, 1.3930, 1.3866]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.6151, 1.0653, 1.2644, 1.4858],\n",
       "          [4.6120, 0.7847, 1.2304, 1.5358],\n",
       "          [4.6097, 0.8560, 1.1747, 1.6515],\n",
       "          ...,\n",
       "          [4.6122, 1.4040, 1.1011, 1.3944],\n",
       "          [4.6138, 0.8793, 1.1207, 1.4099],\n",
       "          [4.6555, 0.9991, 2.1385, 1.6539]],\n",
       "\n",
       "         [[4.6170, 0.7693, 1.5436, 1.5795],\n",
       "          [4.6474, 1.3453, 1.0991, 2.0263],\n",
       "          [4.6782, 0.7445, 1.7705, 1.5261],\n",
       "          ...,\n",
       "          [4.6091, 1.2492, 1.0986, 1.3878],\n",
       "          [4.6062, 0.9485, 1.2800, 2.2615],\n",
       "          [4.6175, 0.8055, 2.0989, 1.4290]],\n",
       "\n",
       "         [[4.6157, 1.4543, 1.1711, 1.5928],\n",
       "          [4.6111, 1.5004, 1.1074, 1.5992],\n",
       "          [4.6076, 1.2130, 1.1524, 1.4631],\n",
       "          ...,\n",
       "          [4.6052, 1.3389, 1.0986, 1.3884],\n",
       "          [4.6068, 0.6946, 1.7096, 1.7685],\n",
       "          [4.6067, 1.6631, 1.1732, 1.5233]]],\n",
       "\n",
       "\n",
       "        [[[4.6660, 1.0514, 1.1029, 1.6691],\n",
       "          [4.6135, 0.6936, 1.0992, 1.3864],\n",
       "          [4.6187, 1.4847, 1.1233, 1.5438],\n",
       "          ...,\n",
       "          [4.6057, 0.8051, 1.1547, 1.5552],\n",
       "          [4.6054, 1.4188, 1.6817, 1.4520],\n",
       "          [4.6070, 1.0193, 1.5203, 1.5731]],\n",
       "\n",
       "         [[4.6104, 0.8627, 1.2424, 1.6552],\n",
       "          [4.6362, 0.6936, 1.2814, 1.3870],\n",
       "          [4.6086, 0.7137, 1.1000, 1.7536],\n",
       "          ...,\n",
       "          [4.6652, 1.5252, 1.1416, 1.3865],\n",
       "          [4.6063, 0.6943, 1.6772, 1.3900],\n",
       "          [4.6068, 1.6043, 1.5706, 1.4119]],\n",
       "\n",
       "         [[4.6082, 0.8140, 1.3381, 1.9399],\n",
       "          [4.6670, 0.7057, 1.1185, 1.4341],\n",
       "          [4.6780, 1.1683, 1.1505, 1.3886],\n",
       "          ...,\n",
       "          [4.6082, 0.7634, 1.2153, 1.6224],\n",
       "          [4.6122, 1.2459, 1.1054, 1.4191],\n",
       "          [4.6057, 1.2983, 1.2152, 1.4254]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.6068, 1.1083, 1.3437, 1.7719],\n",
       "          [4.6080, 1.3629, 1.3287, 1.8276],\n",
       "          [4.6136, 0.7004, 1.3352, 1.8814],\n",
       "          ...,\n",
       "          [4.6073, 0.7630, 1.3042, 1.5025],\n",
       "          [4.6246, 1.4578, 1.1212, 1.8394],\n",
       "          [4.6069, 1.5525, 1.1432, 1.6842]],\n",
       "\n",
       "         [[4.6073, 1.0403, 1.2847, 1.4089],\n",
       "          [4.6052, 1.8959, 1.3149, 1.6490],\n",
       "          [4.6054, 1.4675, 1.6129, 1.5799],\n",
       "          ...,\n",
       "          [4.6163, 1.1538, 1.4415, 1.6602],\n",
       "          [4.6094, 0.7062, 1.1832, 1.4096],\n",
       "          [4.6056, 0.7100, 1.5004, 1.3880]],\n",
       "\n",
       "         [[4.6096, 1.1670, 1.1078, 1.6410],\n",
       "          [4.6092, 1.4363, 1.1221, 1.6497],\n",
       "          [4.6067, 0.6958, 1.1003, 1.4968],\n",
       "          ...,\n",
       "          [4.6064, 1.0352, 1.1486, 1.4582],\n",
       "          [4.6272, 0.6979, 1.3034, 1.8516],\n",
       "          [4.6082, 0.7458, 1.4546, 1.7702]]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'first_feature_idx': 1,\n",
    "    'input_channels': 3}\n",
    "\n",
    "\n",
    "a = 0\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features(full_vol ,config, un_log = True, a = 0, b = 1) -> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    Normalize the features of the volume. One by one to the range [a, b]. \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    first_feature_idx = config['first_feature_idx'] #config.first_feature_idx\n",
    "    last_feature_idx = first_feature_idx + config['input_channels'] - 1 #config.first_feature_idx + config.input_channels - 1\n",
    "\n",
    "\n",
    "    for i in range(first_feature_idx, last_feature_idx + 1):\n",
    "\n",
    "        feature = full_vol[:, :, :, i] \n",
    "\n",
    "        # if config.un_log:\n",
    "        #     feature = torch.exp(feature) - 1\n",
    "\n",
    "        feature_max = feature.max() # could make sure that we are not using information from the future.... But this is not a big deal... \n",
    "        feature_min = 0 #full_vol[:, :, :, i].min()\n",
    "\n",
    "        feature_norm = (b-a)*(feature - feature_min)/(feature_max-feature_min)+a\n",
    "\n",
    "        full_vol[:,:,:,i] = feature_norm\n",
    "\n",
    "    return full_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_channels(tensor, config, un_log = True, a = 0, b = 1) -> torch.Tensor: # not reall a tensor now but an array...\n",
    "\n",
    "    \"\"\"\n",
    "    Normalizes the feature channels for a tensor  to the range [a, b].\n",
    "    Defualt is [-1, 1] to match the batch norm layers.\n",
    "    The input tensor is expected to have the shape [N, C, D, H, W]\n",
    "    Where N is the batch size, C is the number of timesteps, D is the features, H is the height and W is the width.   \n",
    "    \"\"\"\n",
    "\n",
    "    # if un_log:\n",
    "    #     tensor = torch.exp(tensor)\n",
    "\n",
    "    first_feature_idx = config['first_feature_idx'] #config.first_feature_idx\n",
    "    last_feature_idx = first_feature_idx + config['input_channels'] - 1 #config.first_feature_idx + config.input_channels - 1\n",
    "\n",
    "    min_list = []\n",
    "    max_list = []\n",
    "\n",
    "    for i in range(first_feature_idx, last_feature_idx + 1):\n",
    "        #min_list.append(np.min(tensor[ :, :, :, i]))\n",
    "        max_list.append(np.max(tensor[ :, :, :, i]))\n",
    "\n",
    "    # norm_tensor = (b-a)*(tensor - tensor.min())/(tensor.max()-tensor.min())+a\n",
    "\n",
    "    norm_tensor = (b-a)*(tensor - 0)/(8-0)+a # 8 just hardcoded until later...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_channels(tensor, config, pre_logged = True, a = -1, b = 1) -> torch.Tensor:\n",
    "\n",
    "    \"\"\"\n",
    "    Normalizes the feature channels for a tensor  to the range [a, b].\n",
    "    Defualt is [-1, 1] to match the batch norm layers.\n",
    "    The input tensor is expected to have the shape [N, C, D, H, W]\n",
    "    Where N is the batch size, C is the number of timesteps, D is the features, H is the height and W is the width.   \n",
    "    \"\"\"\n",
    "\n",
    "    if pre_logged:\n",
    "        tensor = torch.exp(tensor)\n",
    "\n",
    "    first_feature_idx = config['first_feature_idx'] #config.first_feature_idx\n",
    "    last_feature_idx = config['first_feature_idx'] + config['input_channels'] - 1 #config.first_feature_idx + config.input_channels - 1\n",
    "\n",
    "    min_list = []\n",
    "    max_list = []\n",
    "\n",
    "    for i in range(first_feature_idx, last_feature_idx + 1):\n",
    "        min_list.append(torch.min(tensor[:, :, i, :, :]))\n",
    "        max_list.append(torch.max(tensor[:, :, i, :, :]))\n",
    "\n",
    "    norm_tensor = (b-a)*(tensor - tensor.min())/(tensor.max()-tensor.min())+a\n",
    "    \n",
    "    return norm_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_norm = norm_channels(log_full_vol, config, pre_logged = True, a = 0, b = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(logged_norm.max())\n",
    "print(logged_norm.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(-1.)\n"
     ]
    }
   ],
   "source": [
    "norm_sub_vol = norm_channels(sub_vol, config, pre_logged = True)\n",
    "\n",
    "print(norm_sub_vol.max())\n",
    "print(norm_sub_vol.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, a = 0, b = 1):\n",
    "\n",
    "    \"\"\"Return a normalized x in range [a:b]. Default is [0:1]\"\"\"\n",
    "    x_norm = (b-a)*(x - x.min())/(x.max()-x.min())+a\n",
    "    return(x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.first_feature_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a tensor with dimensions H x W x C\n",
    "tensor = torch.rand(180, 180, 3)  # Replace this with your actual tensor\n",
    "\n",
    "# Calculate maximum and minimum values for each channel (C dimension)\n",
    "max_values, _ = torch.max(tensor, dim=(0, 1))  # Max values for each channel\n",
    "min_values, _ = torch.min(tensor, dim=(0, 1))  # Min values for each channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "seq_len = 300\n",
    "window_size = 180\n",
    " \n",
    "\n",
    "Q  =  torch.randn(batch_size, seq_len, window_size, window_size)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.tensor([[[1,1,1],[1,1,1],[1,1,1]],[[2,2,2],[2,2,2],[2,2,2]],[[3,3,3],[3,3,3],[3,3,3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(Q, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torhc.max(Q, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WarmupDecayLearningRateScheduler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "model = [torch.nn.Parameter(torch.randn(2, 2, requires_grad=True))]\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(model,lr = LR)\n",
    "\n",
    "samples = 10000\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "scheduler = WarmupDecayLearningRateScheduler(optimizer, 32*32*3, 100)\n",
    "for epoch in range(samples):\n",
    "    data_size = 40\n",
    "    for i in range(data_size):\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "\n",
    "plt.plot(range(samples),lr_list,color = 'r')\n",
    "plt.hlines(y=0,xmin=0, xmax=samples,  colors = \"c\",linestyles = \"dashed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "model = [torch.nn.Parameter(torch.randn(2, 2, requires_grad=True))]\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(model,lr = LR)\n",
    "\n",
    "samples = 300\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = samples*0.04, eta_min = 0.00005)\n",
    "for epoch in range(samples):\n",
    "    data_size = 40\n",
    "    for i in range(data_size):\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "\n",
    "plt.plot(range(samples),lr_list,color = 'r')\n",
    "plt.hlines(y=0,xmin=0, xmax=samples,  colors = \"c\",linestyles = \"dashed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "seq_len = 300\n",
    "d_model = 1000\n",
    " \n",
    "\n",
    "Q  =  torch.randn(batch_size, seq_len, d_model)\n",
    "print(Q.shape)\n",
    "\n",
    "\n",
    "\n",
    "n_head = 2\n",
    "\n",
    "Q = Q.view(batch_size, seq_len, n_head, -1).permute(0, 2, 1, 3)\n",
    "print(Q.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(np.log(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.exp(torch.log(torch.tensor(9.0)+1))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_test(x,y) -> torch.Tensor:\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = small_test(1, 2)\n",
    "\n",
    "type(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of size [1, 10, 32, 32]\n",
    "hc = torch.randn(1, 10, 32, 32)\n",
    "\n",
    "split = int(hc.shape[1]/2) # half of the second dimension wich is channels\n",
    "\n",
    "# Split the tensor along dimension 1\n",
    "split_tensors = torch.split(hc, split, dim=1)\n",
    "\n",
    "# The result will be a tuple of two tensors\n",
    "h0, c0 = split_tensors\n",
    "\n",
    "# Print the sizes of the split tensors\n",
    "print(h.size())  # torch.Size([1, 5, 32, 32])\n",
    "print(c.size())  # torch.Size([1, 5, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = c0 * 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = torch.cat([h0, c0], 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the tensor along dimension 1\n",
    "split_tensors = torch.split(hc, split, dim=1)\n",
    "\n",
    "# The result will be a tuple of two tensors\n",
    "h1, c1 = split_tensors\n",
    "\n",
    "# Print the sizes of the split tensors\n",
    "print(h1.size())  # torch.Size([1, 5, 32, 32])\n",
    "print(c1.size())  # torch.Size([1, 5, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 == h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = torch.zeros((1,10,32,32), dtype= torch.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = hc.shape[1]\n",
    "split = int(channels/2)\n",
    "\n",
    "# Split the tensor along dimension 1\n",
    "split_tensors = torch.split(hc, split, dim=1)\n",
    "\n",
    "c.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "padding = kernel_size // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 10\n",
    "dim = 2\n",
    "\n",
    "cube = base**dim\n",
    "\n",
    "print(np.sqrt(cube)) # assuming dim is 2\n",
    "print(np.log10(cube)) # assuming base is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "model = [torch.nn.Parameter(torch.randn(2, 2, requires_grad=True))]\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(model,lr = LR)\n",
    "\n",
    "samples = 300\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = samples*0.04, eta_min = 0.00005)\n",
    "for epoch in range(samples):\n",
    "    data_size = 40\n",
    "    for i in range(data_size):\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "\n",
    "plt.plot(range(samples),lr_list,color = 'r')\n",
    "plt.hlines(y=0,xmin=0, xmax=samples,  colors = \"c\",linestyles = \"dashed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        padding = kernel_size // 2\n",
    "\n",
    "        # Input gate\n",
    "        self.Wxi = nn.Conv2d(input_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.Whi = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.Wxf = nn.Conv2d(input_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.Whf = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.Wxc = nn.Conv2d(input_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.Whc = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.Wxo = nn.Conv2d(input_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.Who = nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h, c = hidden\n",
    "\n",
    "        # Input gate\n",
    "        i_t = torch.sigmoid(self.Wxi(x) + self.Whi(h))\n",
    "        # Forget gate\n",
    "        f_t = torch.sigmoid(self.Wxf(x) + self.Whf(h))\n",
    "        # Cell state\n",
    "        c_tilde = torch.tanh(self.Wxc(x) + self.Whc(h))\n",
    "        c = f_t * c + i_t * c_tilde\n",
    "        # Output gate\n",
    "        o_t = torch.sigmoid(self.Wxo(x) + self.Who(h))\n",
    "        h = o_t * torch.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "\n",
    "# Example usage\n",
    "input_channels = 3\n",
    "hidden_channels = 10\n",
    "kernel_size = 3\n",
    "cell = ConvLSTMCell(input_channels, hidden_channels, kernel_size)\n",
    "x = torch.randn(1, input_channels, 32, 32)\n",
    "hidden_state = (torch.randn(1, hidden_channels, 32, 32), torch.randn(1, hidden_channels, 32, 32))\n",
    "\n",
    "output, new_hidden_state = cell(x, hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = np.random.randint(1,21,[5,5,5])\n",
    "#input = torch.from_numpy(X)\n",
    "\n",
    "B = 1\n",
    "C = 3\n",
    "H = 5\n",
    "W = 5 \n",
    "\n",
    "input = torch.randn(1,3,3,5,5)\n",
    "m = nn.Linear(5, 5, bias=False)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Linear((3,5), (3,5))\n",
    "#input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(1,21,[5,5,5])\n",
    "X_tensor = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "criterion_class = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            weight=None,\n",
    "            gamma=2.0,\n",
    "            reduction='mean'\n",
    "    ):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = torch.sigmoid(input_tensor)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        term = ((1.0 - prob) ** self.gamma) * log_prob\n",
    "        return F.nll_loss(term, target_tensor)\n",
    "        \n",
    "        #return F.nll_loss(term, target_tensor, weight=self.weight, reduction=self.reduction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss01(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, weight=None, size_average=True):\n",
    "        super(FocalLoss01, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.contiguous().view(input.size(0), input.size(1), -1)\n",
    "            input = input.transpose(1,2)\n",
    "            input = input.contiguous().view(-1, input.size(2)).squeeze()\n",
    "        if target.dim()==4:\n",
    "            target = target.contiguous().view(target.size(0), target.size(1), -1)\n",
    "            target = target.transpose(1,2)\n",
    "            target = target.contiguous().view(-1, target.size(2)).squeeze()\n",
    "        elif target.dim()==3:\n",
    "            target = target.view(-1)\n",
    "        else:\n",
    "            target = target.view(-1, 1)\n",
    "\n",
    "        # compute the negative likelyhood\n",
    "        weight = Variable(self.weight)\n",
    "        logpt = -F.cross_entropy(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = -((1-pt)**self.gamma) * logpt\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss02(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, weight=None, size_average=True):\n",
    "        super(FocalLoss02, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # if input.dim()>2:\n",
    "        #     input = input.contiguous().view(input.size(0), input.size(1), -1)\n",
    "        #     input = input.transpose(1,2)\n",
    "        #     input = input.contiguous().view(-1, input.size(2)).squeeze()\n",
    "        # if target.dim()==4:\n",
    "        #     target = target.contiguous().view(target.size(0), target.size(1), -1)\n",
    "        #     target = target.transpose(1,2)\n",
    "        #     target = target.contiguous().view(-1, target.size(2)).squeeze()\n",
    "        # elif target.dim()==3:\n",
    "        #     target = target.view(-1)\n",
    "        # else:\n",
    "        #     target = target.view(-1, 1)\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        # compute.unsqueeze(0)F.cross_entropy(input, target)\n",
    "        logpt = -F.cross_entropy(input, target)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = -((1-pt)**self.gamma) * logpt\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss03(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss03, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        # compute.unsqueeze(0)F.cross_entropy(input, target)\n",
    "        p = 1/(1+np.exp(-input))\n",
    "        loss = -( self.alpha*target + (1-self.alpha)*(1-target) ) * (( 1 - ( target*p + (1-target)*(1-p)) )**self.gamma) * ( target*np.log(p)+(1-target)*np.log(1-p) )\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss04(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss04, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        \n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "        loss = -(target * np.log(input) + (1-target) * np.log(1-input)) #BCE\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss05(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss05, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * np.log(input) + (1-target) * np.log(1-input))\n",
    "        loss = -self.alpha * ((1-np.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST!!!\n",
    "\n",
    "class FocalLoss05(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss05, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * np.log(input) + (1-target) * np.log(1-input))\n",
    "        loss = -self.alpha * ((1-np.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossClass(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLossClass, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "\n",
    "        logpt = (target * torch.log(input) + (1-target) * torch.log(1-input))\n",
    "        loss = -self.alpha * ((1-torch.exp(logpt))**self.gamma) * logpt # for gamma = 0 and alpha = 1 we get the BCELoss\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #WORKS!\n",
    "# class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "#     def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "#         super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.size_average = size_average\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "\n",
    "#         input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "#         input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "\n",
    "#         pos = (-self.alpha * (1-input)**self.gamma * torch.log(input))\n",
    "#         neg = (-(1-self.alpha) * (1-1-input)**self.gamma *  torch.log(1-input))\n",
    "\n",
    "#         #pos = ( (1-input)**self.gamma * torch.log(input))\n",
    "#         #neg = ( (input)**self.gamma *  torch.log(1-input))\n",
    "\n",
    "#         loss = -(pos * target + neg * (1-target))\n",
    "\n",
    "#         # averaging (or not) loss\n",
    "#         if self.size_average:\n",
    "#             return loss.mean()\n",
    "#         else:\n",
    "#             return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "#     def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "#         super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.size_average = size_average\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "\n",
    "#         input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        \n",
    "\n",
    "#         #for logits\n",
    "#         # pos = (-self.alpha * (1-F.sigmoid(input))**self.gamma * F.logsigmoid(input))\n",
    "#         # neg = (-(1-self.alpha) * (-F.sigmoid(input))**self.gamma *  F.logsigmoid(1-input))\n",
    "#         # loss = (pos * target + neg * (1-target))\n",
    "\n",
    "#         # for probs\n",
    "#         input = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "#         pos = (-self.alpha * (1-input)**self.gamma * torch.log(input))\n",
    "#         neg = (-(1-self.alpha) * (1-1-input)**self.gamma *  torch.log(1-input))\n",
    "#         loss = (pos * target + neg * (1-target))\n",
    "\n",
    "#         # averaging (or not) loss\n",
    "#         if self.size_average:\n",
    "#             return loss.mean()\n",
    "#         else:\n",
    "#             return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class stableBalancedFocalLossClass(nn.Module):\n",
    "\n",
    "#     def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "#         super(stableBalancedFocalLossClass, self).__init__()\n",
    "\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.size_average = size_average\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "\n",
    "#         input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "\n",
    "#         # fo   r probs\n",
    "#         min_ind = torch.exp(torch.tensor(-100)) # almost 0\n",
    "#         max_ind = torch.tensor(1.0)- torch.exp(torch.tensor(-10)) # almost 1\n",
    "#         input = torch.clamp(input, min = min_ind, max = max_ind) # so we do not log(0)\n",
    "\n",
    "#         pos = (-self.alpha * (1-input)**self.gamma * torch.log(input))\n",
    "#         neg = (-(1-self.alpha) * (1-1-input)**self.gamma *  torch.log(1-input))\n",
    "#         loss = (pos * target + neg * (1-target))\n",
    "\n",
    "#         # Seem pytorch have something like this..\n",
    "#         if loss.mean() >= max_ind:\n",
    "#             floor = 10\n",
    "#         else:\n",
    "#             floor = 1\n",
    "\n",
    "#         loss =  loss * 2 * floor # *2 is just a constant to make it more like BCE\n",
    "\n",
    "#         # averaging (or not) lossinput = torch.clamp(input, min = torch.exp(torch.tensor(-100))) # so we do not log(0)\n",
    "        \n",
    "#         if self.size_average:\n",
    "#             return loss.mean()\n",
    "#         else:\n",
    "#             return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(p):\n",
    "    return (p * np.log(1/p)).sum()\n",
    "\n",
    "def cross_entropy(p, q):\n",
    "    return -(p * np.log(q)).sum() # same as (p * np.log(1/q)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedFocalLossClass(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=0.5, size_average=True):\n",
    "        super(BalancedFocalLossClass, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        \n",
    "        # Numerical stabilityt pytorhc trick.\n",
    "        log_input = torch.clamp(torch.log(input), -100, 100)\n",
    "        log_input_rev = torch.clamp(torch.log(1-input), -100, 100)\n",
    "\n",
    "        # for probs\n",
    "        pos = (-self.alpha * (1-input)**self.gamma * log_input)\n",
    "        neg = (-(1-self.alpha) * (1-1-input)**self.gamma * log_input_rev)\n",
    "        \n",
    "        loss = (pos * target + neg * (1-target))\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_class = nn.BCELoss()\n",
    "\n",
    "x1 = torch.rand([ 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion_focal01 = FocalLoss01(gamma=1)\n",
    "# criterion_focal02 = FocalLoss02(gamma=1, size_average=False)\n",
    "# criterion_focal03 = FocalLoss03(gamma=1, alpha = 1, size_average=True)\n",
    "\n",
    "# criterion_focal04 = FocalLoss04(gamma=0)\n",
    "# criterion_focal05 = FocalLoss05()\n",
    "\n",
    "#criterion_focal06 = FocalLossClass()\n",
    "criterion_focal07 = BalancedFocalLossClass(gamma=2, alpha=0.05)\n",
    "# criterion_focal07 = stableBalancedFocalLossClass(gamma=0, alpha=0.5)\n",
    "\n",
    "\n",
    "# print(criterion_focal01(x1.unsqueeze(0), x1_b.unsqueeze(0)))\n",
    "# print(criterion_focal02(x1, x1_b))\n",
    "# print(criterion_focal03(x1, x1_b))\n",
    "\n",
    "\n",
    "# print(criterion_focal04(x1, x1_b))\n",
    "\n",
    "# print(criterion_focal05(x1, x1_b))\n",
    "\n",
    "#print(criterion_focal06(x1, x1_b))\n",
    "\n",
    "print(criterion_focal07(x1, x1_b)) \n",
    "\n",
    "\n",
    "print(criterion_class(x1, x1_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal07 = BalancedFocalLossClass(gamma=0, alpha=0.5)\n",
    "\n",
    "print(criterion_focal07(x1, x1_b)) \n",
    "print(criterion_class(x1, x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([ 3 ,100, 100]) \n",
    "\n",
    "x2 = torch.zeros([ 3 ,100, 100]) + torch.tensor(1.0) - torch.exp(torch.tensor(0))\n",
    "\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "\n",
    "print(criterion_focal07(x2, x1_b)*2) \n",
    "print(criterion_class(x2, x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([ 3 ,100, 100]) \n",
    "\n",
    "x2 = torch.zeros([ 3 ,100, 100]) + torch.tensor(1.0) - torch.exp(torch.tensor(-12))\n",
    "\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "if x2.mean() > torch.tensor(1.0) - torch.exp(torch.tensor(-15)):\n",
    "    floor = 10\n",
    "else:\n",
    "    floor = 1\n",
    "\n",
    "print(criterion_focal07(x2, x1_b) * floor) \n",
    "print(criterion_class(x2, x1_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_class01 = BalancedFocalLossClass(gamma=0.0, alpha=0.75)\n",
    "criterion_focal_class02 = BalancedFocalLossClass(gamma=2.0, alpha=0.25)\n",
    "criterion_focal_class03 = BalancedFocalLossClass(gamma=5.0, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'focal, gamma = 0, alpha = 1 : \\t {criterion_focal_class01(x1, x1_b)}')\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_class02(x1, x1_b)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_class03(x1, x1_b)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.logsigmoid(torch.tensor(.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32)\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "RT = torch.rand([ 3 ,100, 100]) \n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BalancedFocalLossClass(gamma=2, alpha=0.95)\n",
    "\n",
    "\n",
    "print(criterion(ZT, IT)) \n",
    "print(criterion(RT, IT)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss_reg, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        input = torch.clamp(input, min = np.exp(-100)) # so we do not log(0)\n",
    "\n",
    "        mse = (target - input)**2\n",
    "\n",
    "        loss = self.alpha * ((1-np.exp(mse))**self.gamma) * mse # for gamma = 0 and alpha = 1 we get the mse\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg = nn.MSELoss()\n",
    "\n",
    "x1 = torch.rand([ 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg01 = FocalLoss_reg(gamma=0)\n",
    "criterion_focal_reg02 = FocalLoss_reg(gamma=1)\n",
    "criterion_focal_reg03 = FocalLoss_reg(gamma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32)\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "OT = torch.zeros([ 3 ,100, 100]) + 1\n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: \\t\\t\\t\\t {criterion_reg(ZT, IT)}')\n",
    "print(f'focal, gamma = 0, alpha = 1 : \\t {criterion_focal_reg01(ZT, IT)}')\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_reg02(ZT, IT)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_reg03(ZT, IT)}')\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'focal, gamma = 1, alpha = 1 : \\t {criterion_focal_reg01(OT, IT)}')\n",
    "print(f'focal, gamma = 2, alpha = 1 : \\t {criterion_focal_reg02(OT, IT)}')\n",
    "print(f'focal, gamma = 3, alpha = 1 : \\t {criterion_focal_reg03(OT, IT)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(input, target):\n",
    "    loss = (target - input)**2\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(input, target):\n",
    "    se = target - input\n",
    "    lse = np.exp(se)  #torch.clamp(se, min = np.exp(-100)))\n",
    "    mlse = lse.mean()\n",
    "\n",
    "    return mlse\n",
    "\n",
    "    # return - np.log(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand([ 3 ,100, 100]) * 10\n",
    "\n",
    "# targer\n",
    "IT = torch.tensor(np.stack([np.identity(100), np.identity(100),  np.identity(100)]), dtype= torch.float32) * noise\n",
    "\n",
    "# candidates\n",
    "ZT = torch.zeros([ 3 ,100, 100])\n",
    "OT = (torch.zeros([ 3 ,100, 100]) + 1 ) * noise\n",
    "\n",
    "# the loss must priorities 0T over ZT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE(ZT, IT))\n",
    "print(MSE(OT, IT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OT.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=1, size_average=True):\n",
    "        super(FocalLoss_reg, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0)\n",
    "        #input = torch.clamp(input, min = np.exp(-100)) # could do this for no negatives???\n",
    "\n",
    "        error = target - input\n",
    "        exp_error = np.exp(error)  #torch.clamp(se, min = np.exp(-100)))\n",
    "        loss = exp_error.mean()\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShrinkageLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, a=10, c=0.2, size_average=True):\n",
    "        super(ShrinkageLoss, self).__init__()\n",
    "\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "\n",
    "        input, target = input.unsqueeze(0), target.unsqueeze(0) \n",
    "\n",
    "        l = torch.abs(target - input)     #F.l1_loss(input, target)\n",
    "\n",
    "        loss = (l**2)/(1 + torch.exp(self.a*(self.c-l)))\n",
    "\n",
    "        # averaging (or not) loss\n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg = ShrinkageLoss(a=10, c=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal_reg = ShrinkageLoss(a=1, c=12)\n",
    "\n",
    "print(criterion_focal_reg(ZT, IT))\n",
    "print(criterion_focal_reg(OT, IT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shannon_entropy(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy(x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy( x1_b, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-(x1_b * np.log(x1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1_b * (np.log(1/x1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion_focal02(x1, x1_b))\n",
    "print(criterion_class(x1, x1_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 3\n",
    "\n",
    "if t == 1 or t == 0:\n",
    "    print('cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = RMSLELoss()\n",
    "print(f'sgoairb: {cr}\\n..................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([3,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal = FocalLoss2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion_focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_focal(x1.unsqueeze(0), x1_b.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "sigmoid_focal_loss(x1, x1_b, reduction= 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand([1, 3 ,100, 100])#.type(torch.LongTensor)\n",
    "x1_b = (x1 > 0.5)*1.0 \n",
    "\n",
    "criterion_focal(x1.reshape(-1), x1_b.reshape(-1).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "#x1 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x2 = torch.randn([1, 3 ,100, 100]).float()\n",
    "\n",
    "x3 = torch.randn([1, 3 ,100, 100]).float()\n",
    "x4 = torch.randn([1, 3 ,100, 100]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1_ = x1.reshape(-1)\n",
    "# x2_ = x2.reshape(-1)\n",
    "\n",
    "# mask = x1_ > 0\n",
    "\n",
    "# x1_[mask].shape\n",
    "\n",
    "# criterion_reg(x1_, x2_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(losses_list) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    x1_ = x1[:,i,:,:].reshape(-1)\n",
    "    x2_ = x2[:,i,:,:].reshape(-1)\n",
    "    mask = (x3[:,i,:,:].reshape(-1) > 0.0001) | (x4[:,i,:,:].reshape(-1) > 0.0001)\n",
    "\n",
    "    losses_list.append(criterion_reg(x1_[mask], x2_[mask]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    losses_list.append(criterion_class(t1_pred_class[:,i,:,:], t1_binary[:,i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    losses_list.append(torch.tensor(1.0))\n",
    "\n",
    "for i in range(3):\n",
    "    losses_list.append(torch.tensor(2.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.stack(losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[-3:].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 32\n",
    "D = 16 \n",
    "\n",
    "\n",
    "X = torch.rand(1, 3, D, D)\n",
    "H = torch.rand(1, hidden_channels, D, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H+X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c2 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c3 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c4 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)\n",
    "\n",
    "c5 = torch.nn.Conv2d(32,32, 3, padding= 'same')\n",
    "c6 = torch.nn.Conv2d(32,32, 3, padding= 'same', bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.sigmoid(c1(X) + c2(H))\n",
    "\n",
    "R = torch.sigmoid(c3(X) + c4(H))\n",
    "\n",
    "H_tilde = torch.tanh(c5(X) + c6(torch.mul(R,H)))\n",
    "\n",
    "H = torch.mul(torch.mul(Z,H) + (1 - Z), H_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.zeros([1,48,3,180,180])\n",
    "tens  =torch.tensor(vol)\n",
    "\n",
    "torch.stack((tens,tens)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.zeros([1,48,3,180,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[:,:,0,:,:] = 1\n",
    "vol[:,:,1,:,:] = 2\n",
    "vol[:,:,2,:,:] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol.shape)\n",
    "print(vol[:,:,0,:,:].mean())\n",
    "print(vol[:,:,1,:,:].mean())\n",
    "print(vol[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = vol.shape[0] # batch size. Always 1\n",
    "C = vol.shape[1] # months\n",
    "D = vol.shape[2] # features\n",
    "H = vol.shape[3] # height\n",
    "W = vol.shape[4] # width\n",
    "\n",
    "vol2 = vol.reshape(N, C*D, H, W)\n",
    "print(vol2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = transforms.Compose([transforms.RandomRotation((0,360)), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])\n",
    "transformer = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation (can be turned of for final experiments)        \n",
    "vol2 = transformer(torch.tensor(vol2)) # rotations and flips # skip for now... '''''''''''''''''''''''''''''''''''''''''''''''''''''' bug only take 4 dims.. could just squezze the batrhc dom and then give it again afterwards?#train_tensor = train_tensor.reshape(N, C, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol3 = vol2.reshape(N,C,D,H,W)\n",
    "print(vol3.shape)\n",
    "print(vol3[:,:,0,:,:].mean())\n",
    "print(vol3[:,:,1,:,:].mean())\n",
    "print(vol3[:,:,2,:,:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(vol3 == vol).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e07914b3d36b3c0ae84e5e97633abec307a3dfe696e94a6042eabf44e48503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
