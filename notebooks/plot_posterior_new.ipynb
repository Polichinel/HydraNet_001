{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     posterior_dict \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file)\n\u001b[1;32m     12\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlocal_dir\u001b[39m}\u001b[39;00m\u001b[39m/test_tensor_48_calib.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m---> 13\u001b[0m     test_tensor \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(file)\n\u001b[1;32m     15\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlocal_dir_raw\u001b[39m}\u001b[39;00m\u001b[39m/viewser_monthly_vol_calib.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     16\u001b[0m     views_vol \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/storage.py:240\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m--> 240\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(io\u001b[39m.\u001b[39;49mBytesIO(b))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/serialization.py:795\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 795\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/serialization.py:1012\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1010\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1011\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1012\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1014\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1016\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/serialization.py:958\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    954\u001b[0m     obj\u001b[39m.\u001b[39m_torch_load_uninitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     deserialized_objects[root_key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m--> 958\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(obj, location),\n\u001b[1;32m    959\u001b[0m         dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    961\u001b[0m typed_storage \u001b[39m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m view_metadata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 215\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    216\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2023/lib/python3.10/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "#local_dir = '/home/simon/Documents/Articles/ConflictNet/data/generated/'\n",
    "#local_dir_raw = '/home/simon/Documents/Articles/ConflictNet/data/raw/'\n",
    "\n",
    "local_dir = '/home/number_one/Documents/scripts/conflictNet/data/generated'\n",
    "local_dir_raw = '/home/number_one/Documents/scripts/conflictNet/data/raw'\n",
    "timelaps_dir = '/home/number_one/Documents/scripts/conflictNet/reports/timelapse/viewser_calib_sbnsos'\n",
    "test_month = 48\n",
    "\n",
    "with open(f'{local_dir}/posterior_dict_48_calib.pkl', 'rb') as file:\n",
    "    posterior_dict = pickle.load(file)\n",
    "\n",
    "with open(f'{local_dir}/test_tensor_48_calib.pkl', 'rb') as file:\n",
    "    test_tensor = pickle.load(file)\n",
    "\n",
    "with open(f'{local_dir_raw}/viewser_monthly_vol_calib.pkl', 'rb') as file:\n",
    "    views_vol = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert overall ap score.\n",
    "\n",
    "def plt_trio(test_month, timelaps_dir, posterior_dict, views_vol):\n",
    "\n",
    "    posterior_list = posterior_dict['posterior_list']\n",
    "    posterior_list_class = posterior_dict['posterior_list_class']\n",
    "    out_of_sample_tensor = posterior_dict['out_of_sample_tensor']\n",
    "    out_of_sample_numpy = out_of_sample_tensor.numpy()\n",
    "\n",
    "    mean_class_pred = np.array(posterior_list_class[test_month]).mean(axis=0)\n",
    "    mean_pred = np.array(posterior_list[test_month]).mean(axis=0)\n",
    "    true_obs = out_of_sample_numpy[:,test_month,:,:].squeeze()\n",
    "\n",
    "    std_pred = np.array(posterior_list[test_month]).std(axis=0)\n",
    "\n",
    "    # min/max for plotting\n",
    "    min_true = out_of_sample_numpy.min()\n",
    "    max_true = out_of_sample_numpy.max()\n",
    "    min_pred = np.array(posterior_list).min()\n",
    "    max_pred = np.array(posterior_list).max()\n",
    "    min_pred_class = np.array(posterior_list_class).min()\n",
    "    max_pres_class = np.array(posterior_list_class).max()\n",
    "\n",
    "    min_pred_std = np.array(posterior_list).mean(axis=0).std(axis = 0).min()\n",
    "    max_pred_std = np.array(posterior_list).mean(axis=0).std(axis = 0).max()\n",
    "\n",
    "    all_abs_error = np.abs(out_of_sample_numpy.squeeze() - np.array(posterior_list).mean(axis = 0))\n",
    "    min_error = all_abs_error.min()\n",
    "    max_error = all_abs_error.max()\n",
    "\n",
    "    # abs error\n",
    "    abs_error = np.abs(true_obs - mean_pred)\n",
    "\n",
    "\n",
    "    # Confucsion\n",
    "    threshold = 0.2 # there is a good way to do this... You have just forgotten it...\n",
    "\n",
    "    binary_pred = (mean_class_pred > threshold) * 1 \n",
    "    binary_true = (true_obs > 0)*1\n",
    "\n",
    "    TP = ((binary_pred == 1) & (binary_true == 1)).astype('int')\n",
    "    FP = ((binary_pred == 1) & (binary_true == 0)).astype('int')*2\n",
    "    FN = ((binary_pred == 0) & (binary_true == 1)).astype('int')*3\n",
    "    # TN = ((binary_pred == 0) & (binary_true == 0)).astype('int')*4\n",
    "\n",
    "\n",
    "    confusion_map = TP + FP + FN #+ TN # TN per defualt 0\n",
    "\n",
    "    # TN gray, TP green, FP blue, FN red\n",
    "    colors = [ (0.5, 0.5, 0.5), (0, 1, 0), (0, 0, 1), (1, 0, 0)]  # R, G, B\n",
    "    cmap_name = 'catagorical4'\n",
    "    cat_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=4)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=[30,20])\n",
    "\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.title(f'true, month {test_month}')\n",
    "    true_obs_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), true_obs)\n",
    "    plt.imshow(true_obs_masked, cmap = 'rainbow', vmin= min_true, vmax=max_true, aspect= 'equal', interpolation = None)\n",
    "    plt.colorbar(shrink = 0.6, label = 'observed magnitude y, i.e. log(best)')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.title(f'pred, month {test_month}')\n",
    "    mean_pred_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), mean_pred)\n",
    "    plt.imshow(mean_pred_masked, cmap = 'rainbow', vmin= min_pred, vmax=max_pred, aspect= 'equal', interpolation = None)\n",
    "    plt.colorbar(shrink = 0.6, label = 'predictited magnitude, ŷ ')\n",
    "\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.title(f'pred class, month {test_month}')\n",
    "    mean_class_pred_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), mean_class_pred)\n",
    "    plt.imshow(mean_class_pred_masked, cmap = 'rainbow', vmin= min_pred_class, vmax=max_pres_class, aspect= 'equal', interpolation = None)\n",
    "    plt.colorbar(shrink = 0.6, label = 'predictited probability, ỹ')\n",
    "\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.title(f'absolute error, month {test_month}')\n",
    "    abs_error_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), abs_error)\n",
    "    plt.imshow(abs_error_masked, cmap = 'rainbow', vmin=min_error, vmax=max_error, aspect= 'equal', interpolation = None) # min and max are not constant here!\n",
    "    plt.colorbar(shrink = 0.6, label = 'absolute error, |y-ŷ|')\n",
    "\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.title(f'pred std, month {test_month}')  # wonrg title\n",
    "    std_pred_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), std_pred)\n",
    "    plt.imshow(std_pred_masked, cmap = 'rainbow', vmin=min_pred_std, vmax=max_pred_std, aspect= 'equal', interpolation = None)\n",
    "    plt.colorbar(shrink = 0.6,  label = 'ensemble std (predicted magnitude, ŷ)')\n",
    "\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.title(f'confusion_map (T=0.2)pred std, month {test_month}')  # wonrg title\n",
    "    confusion_map_masked = np.ma.masked_where((views_vol[-48,:,:,4] == 0), confusion_map)\n",
    "    plt.imshow(confusion_map_masked, cmap = cat_cmap, vmin=0, vmax=3, aspect= 'equal', interpolation = None)\n",
    "    cbar = plt.colorbar(ticks = np.linspace(0.4,2.6,4), shrink = 0.6)\n",
    "    cbar.set_ticklabels(['TN', 'TP', 'FP', 'FN'])\n",
    "\n",
    "    plt.subplots_adjust(hspace = -0.1, wspace = 0.1)\n",
    "\n",
    "    fig_title = f'trio_{str(test_month).zfill(2)}'\n",
    "    plt.savefig(timelaps_dir + '/' + fig_title + '.JPG', bbox_inches=\"tight\")\n",
    "    plt.cla() # idk if this is also needed..\n",
    "    plt.close('all') # so they do not display or take up mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_trio(test_month, timelaps_dir, posterior_dict, views_vol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e07914b3d36b3c0ae84e5e97633abec307a3dfe696e94a6042eabf44e48503"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
