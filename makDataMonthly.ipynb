{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gwno():\n",
    "\n",
    "    location = '/home/projects/ku_00017/data/raw/PRIO'\n",
    "    #location = '/home/simon/Documents/Bodies/data/PRIO'#local\n",
    "    #path_gwno = location + '/PRIO-GRID Yearly Variables for 2003-2009 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "    path_gwno = location + '/PRIO-GRID Yearly Variables for 1989-2014 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "\n",
    "    # why not just go 1989 - 2019 like ucdp...\n",
    "\n",
    "    gwno = pd.read_csv(path_gwno)\n",
    "\n",
    "    return gwno\n",
    "\n",
    "def get_prio_shape():\n",
    "\n",
    "    location = '/home/projects/ku_00017/data/raw/PRIO'\n",
    "    #location = '/home/simon/Documents/Bodies/data/PRIO'#local\n",
    "    path_prio = location + '/priogrid_shapefiles.zip'\n",
    "\n",
    "    if os.path.isfile(path_prio) == True:\n",
    "        \n",
    "        print('File already downloaded')\n",
    "        prio_grid = gpd.read_file('zip://' + path_prio)\n",
    "\n",
    "    else:\n",
    "        print('Beginning file download PRIO...')\n",
    "        url_prio = 'http://file.prio.no/ReplicationData/PRIO-GRID/priogrid_shapefiles.zip'\n",
    "\n",
    "        urllib.request.urlretrieve(url_prio, path_prio)\n",
    "        prio_grid = gpd.read_file('zip://' + path_prio)\n",
    "\n",
    "    return prio_grid\n",
    "\n",
    "\n",
    "def get_gwno():\n",
    "\n",
    "    location = '/home/projects/ku_00017/data/raw/PRIO'\n",
    "    #location = '/home/simon/Documents/Bodies/data/PRIO' #local\n",
    "    #path_gwno = location + '/PRIO-GRID Yearly Variables for 2003-2009 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "    path_gwno = location + '/PRIO-GRID Yearly Variables for 1989-2014 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "\n",
    "    # why not just go 1989 - 2019 like ucdp...\n",
    "\n",
    "    gwno = pd.read_csv(path_gwno)\n",
    "\n",
    "    return gwno\n",
    "\n",
    "\n",
    "def get_ucdp():\n",
    "\n",
    "    location = '/home/projects/ku_00017/data/raw/UCDP'\n",
    "    #location = '/home/simon/Documents/Bodies/data/UCDP' #local\n",
    "    path_ucdp = location + \"/ged201-csv.zip\"\n",
    "    \n",
    "    if os.path.isfile(path_ucdp) == True:\n",
    "        print('file already downloaded')\n",
    "        ucdp = pd.read_csv(path_ucdp)\n",
    "\n",
    "\n",
    "    else: \n",
    "        print('Beginning file download UCDP...')\n",
    "\n",
    "        url_ucdp = 'https://ucdp.uu.se/downloads/ged/ged201-csv.zip'\n",
    "    \n",
    "        urllib.request.urlretrieve(url_ucdp, path_ucdp)\n",
    "        ucdp = pd.read_csv(path_ucdp)\n",
    "\n",
    "    return ucdp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_months(ucdp, world_grid):\n",
    "\n",
    "    diff = ucdp['year'].max() - world_grid['year'].max()\n",
    "\n",
    "    subset_list = []\n",
    "\n",
    "    for i in np.arange(1, diff+1, 1):\n",
    "\n",
    "        subset = world_grid[world_grid['year'] == world_grid['year'].max()].copy()\n",
    "        subset['year'] = world_grid['year'].max() + i\n",
    "\n",
    "        subset_list.append(subset)\n",
    "\n",
    "    new_years = pd.concat(subset_list)\n",
    "    world_grid_all_years = pd.concat([world_grid, new_years])\n",
    "\n",
    "    month = [str(i).zfill(2) for i in np.arange(1,13,1)]\n",
    "    world_grid_all_years.loc[:,'month'] = world_grid_all_years.apply(lambda _: month, axis=1)\n",
    "    world_grid_all_months = world_grid_all_years.sort_values('year').explode('month').copy()\n",
    "    world_grid_all_months['year_months_start'] =  world_grid_all_months['year'].astype(str) + '-' +  world_grid_all_months['month'].astype(str)\n",
    "\n",
    "    year_months = sorted(world_grid_all_months['year_months_start'].unique())\n",
    "    ts = len(year_months)\n",
    "    month_ids = np.arange(109, ts + 109, 1)\n",
    "    month_id_dict = dict(zip(year_months,month_ids))\n",
    "    month_df = pd.DataFrame({'year_months_start' : year_months, 'month_id': month_ids})\n",
    "    world_grid_all_months_id = world_grid_all_months.merge(month_df, how = 'left', on = 'year_months_start')\n",
    "\n",
    "    return world_grid_all_months_id\n",
    "\n",
    "\n",
    "def prio_ucdp_merge(ucdp, world_grid_all_months):\n",
    "    ucdp_tmp1 = ucdp.copy()\n",
    "\n",
    "    ucdp_tmp1['year_months_start'] = ucdp_tmp1['date_start'].str.slice(start = 0, stop = 7) # Date YYYY-MM-DD\n",
    "    ucdp_tmp1['year_months_end'] = ucdp_tmp1['date_start'].str.slice(start = 0, stop = 7) # Date YYYY-MM-DD\n",
    "\n",
    "\n",
    "    mask1 = (ucdp_tmp1['year'] != ucdp_tmp1['year_months_start'].str.slice(start = 0, stop = 4).astype(int))\n",
    "    mask2 = (ucdp_tmp1['year'] != ucdp_tmp1['year_months_end'].str.slice(start = 0, stop = 4).astype(int))\n",
    "\n",
    "    # correction. Note that end and start year for the four entries that is corrected is the same.\n",
    "    ucdp_tmp1.loc[mask1 | mask2, 'year'] = ucdp_tmp1.loc[mask1 | mask2,'year_months_start'].str.slice(start = 0, stop = 4).astype(int)\n",
    "\n",
    "    feature_list = ['deaths_a','deaths_b', 'deaths_civilians', 'deaths_unknown','best', 'high', 'low']\n",
    "\n",
    "    ucdp_monthly_unit = ucdp_tmp1.groupby(['year_months_start','year', 'priogrid_gid']).sum()[feature_list].reset_index()\n",
    "    ucdp_monthly_unit.rename(columns={'priogrid_gid':'gid'}, inplace=True)\n",
    "\n",
    "    ucdp_monthly_unit['log_best'] = np.log(ucdp_monthly_unit['best'] +1)\n",
    "    ucdp_monthly_unit['log_low'] = np.log(ucdp_monthly_unit['low'] +1)\n",
    "    ucdp_monthly_unit['log_high'] = np.log(ucdp_monthly_unit['high'] +1)\n",
    "\n",
    "    prio_ucdp_df = world_grid_all_months.merge(ucdp_monthly_unit, how = 'left', on = ['gid', 'year_months_start', 'year'])\n",
    "    prio_ucdp_df.fillna(0, inplace=True)\n",
    "\n",
    "    return prio_ucdp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and you can also add some prio stuff here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_volumn(df):\n",
    "\n",
    "    # we start with wat we know - but there is no reason not to try with more down til line.\n",
    "\n",
    "    sub_df = df[['gid', 'xcoord', 'ycoord', 'month_id', 'best', 'low', 'high', 'log_best', 'log_low', 'log_high']].copy() # remove the everything also the geo col.\n",
    "\n",
    "    sub_df_sorted = sub_df.sort_values(['month_id', 'ycoord', 'xcoord'], ascending = [True, False, True])\n",
    "\n",
    "    # try to keep the jazz\n",
    "    #grid_ucdpS = grid_ucdpS[['gid','best', 'low',  'high', 'log_best', 'log_low', 'log_high']].copy() # remove the everything also the geo col. But keep gid. Why not.\n",
    "\n",
    "    x_dim = sub_df['xcoord'].unique().shape[0]\n",
    "    y_dim = sub_df['ycoord'].unique().shape[0]\n",
    "    z_dim = sub_df['month_id'].unique().shape[0]\n",
    "\n",
    "    ucpd_vol = np.array(sub_df_sorted).reshape((z_dim, y_dim, x_dim, -1))\n",
    "\n",
    "    return ucpd_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prio_ucdp():\n",
    "\n",
    "    prio_grid = get_prio_shape()\n",
    "    gwno = get_gwno()\n",
    "    ucdp = get_ucdp()\n",
    "\n",
    "    world_grid = prio_grid.merge(gwno, how = 'right', on = 'gid') # if you just merge this on outer I think you get the full grid needed for R-UNET\n",
    "    world_grid_all_months = add_months(ucdp, world_grid)\n",
    "    prio_ucdp = prio_ucdp_merge(ucdp, world_grid_all_months)\n",
    "\n",
    "    prio_ucdp =  pd.DataFrame(prio_ucdp.drop(columns = ['geometry'])) # let this go in some function...\n",
    "\n",
    "    return prio_ucdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded\n",
      "file already downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1952240/298590805.py:52: DtypeWarning: Columns (47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ucdp = pd.read_csv(path_ucdp)\n",
      "/tmp/ipykernel_1952240/1121558992.py:47: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ucdp_monthly_unit = ucdp_tmp1.groupby(['year_months_start','year', 'priogrid_gid']).sum()[feature_list].reset_index()\n"
     ]
    }
   ],
   "source": [
    "prio_ucdp = get_prio_ucdp()\n",
    "ucpd_vol = make_volumn(prio_ucdp)\n",
    "\n",
    "\n",
    "location = '/home/projects/ku_00017/data/raw/conflictNet'\n",
    "#location = '/home/simon/Documents/Articles/ConflictNet/data/raw'\n",
    "\n",
    "print('Saving pickle')\n",
    "file_name = \"/ucpd_monthly_vol.pkl\"\n",
    "output = open(location + file_name, 'wb')\n",
    "pickle.dump(ucpd_vol, output)\n",
    "output.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('geo_env_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5129632b36db574984207cd0a6a7eba6bc5bd4272ef35f5fb4074faf0a719fbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
