{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gwno():\n",
    "\n",
    "    location = '/home/projects/ku_00017/data/raw/PRIO'\n",
    "    location = '/home/simon/Documents/Bodies/data/PRIO'#local\n",
    "    #path_gwno = location + '/PRIO-GRID Yearly Variables for 2003-2009 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "    path_gwno = location + '/PRIO-GRID Yearly Variables for 1989-2014 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "\n",
    "    # why not just go 1989 - 2019 like ucdp...\n",
    "\n",
    "    gwno = pd.read_csv(path_gwno)\n",
    "\n",
    "    return gwno\n",
    "\n",
    "def get_prio_shape():\n",
    "\n",
    "    #location = '/home/projects/ku_00017/data/raw/PRIO'\n",
    "    location = '/home/simon/Documents/Bodies/data/PRIO'#local\n",
    "    path_prio = location + '/priogrid_shapefiles.zip'\n",
    "\n",
    "    if os.path.isfile(path_prio) == True:\n",
    "        \n",
    "        print('File already downloaded')\n",
    "        prio_grid = gpd.read_file('zip://' + path_prio)\n",
    "\n",
    "        prio_grid =  pd.DataFrame(prio_grid.drop(columns = ['geometry']))\n",
    "\n",
    "    else:\n",
    "        print('Beginning file download PRIO...')\n",
    "        url_prio = 'http://file.prio.no/ReplicationData/PRIO-GRID/priogrid_shapefiles.zip'\n",
    "\n",
    "        urllib.request.urlretrieve(url_prio, path_prio)\n",
    "        prio_grid = gpd.read_file('zip://' + path_prio)\n",
    "\n",
    "        prio_grid =  pd.DataFrame(prio_grid.drop(columns = ['geometry']))\n",
    "\n",
    "    return prio_grid\n",
    "\n",
    "\n",
    "def get_gwno():\n",
    "\n",
    "    #location = '/home/projects/ku_00017/data/raw/PRIO'\n",
    "    location = '/home/simon/Documents/Bodies/data/PRIO' #local\n",
    "    #path_gwno = location + '/PRIO-GRID Yearly Variables for 2003-2009 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "    path_gwno = location + '/PRIO-GRID Yearly Variables for 1989-2014 - 2022-06-16.csv' #https://grid.prio.org/#/download # need to figrue out the API\n",
    "\n",
    "    # why not just go 1989 - 2019 like ucdp...\n",
    "\n",
    "    gwno = pd.read_csv(path_gwno)\n",
    "\n",
    "    return gwno\n",
    "\n",
    "\n",
    "def get_ucdp():\n",
    "\n",
    "    #location = '/home/projects/ku_00017/data/raw/UCDP'\n",
    "    location = '/home/simon/Documents/Bodies/data/UCDP' #local\n",
    "    path_ucdp = location + \"/ged201-csv.zip\"\n",
    "    \n",
    "    if os.path.isfile(path_ucdp) == True:\n",
    "        print('file already downloaded')\n",
    "        ucdp = pd.read_csv(path_ucdp, low_memory=False)\n",
    "\n",
    "\n",
    "    else: \n",
    "        print('Beginning file download UCDP...')\n",
    "\n",
    "        url_ucdp = 'https://ucdp.uu.se/downloads/ged/ged201-csv.zip'\n",
    "    \n",
    "        urllib.request.urlretrieve(url_ucdp, path_ucdp)\n",
    "        ucdp = pd.read_csv(path_ucdp, low_memory=False)\n",
    "\n",
    "\n",
    "    # just to save ram for now !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    sub_years = sorted(ucdp['year'].unique())[:4]\n",
    "    ucdp = ucdp[ucdp['year'].isin(sub_years)]\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    ucdp['month'] = pd.to_datetime(ucdp['date_start']).dt.month\n",
    "    ucdp.rename(columns= {'priogrid_gid' : 'gid'}, inplace= True)\n",
    "\n",
    "    # ONLY STATE BASED!\n",
    "    ucdp = ucdp[ucdp['type_of_violence'] == 2].copy()\n",
    "\n",
    "    feature_list = ['month','year', 'gid', 'deaths_a','deaths_b', 'deaths_civilians', 'deaths_unknown','best', 'high', 'low']\n",
    "\n",
    "    ucdp_monthly_unit = ucdp.loc[:,feature_list].groupby(['month','year', 'gid']).sum().reset_index()\n",
    "    ucdp_monthly_unit['log_best'] = np.log(ucdp_monthly_unit['best'] +1)\n",
    "    ucdp_monthly_unit['log_low'] = np.log(ucdp_monthly_unit['low'] +1)\n",
    "    ucdp_monthly_unit['log_high'] = np.log(ucdp_monthly_unit['high'] +1)\n",
    "\n",
    "    ucdp_monthly_unit['in_ucdp'] = True # handy later when I wnat to remove water and stuff.\n",
    "\n",
    "    return ucdp_monthly_unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_views_data():\n",
    "\n",
    "    path_views = '/home/simon/Documents/Articles/ConflictNet/data/raw/ucdp_views_priogrid_month.csv.zip'\n",
    "    #path_views = '/home/projects/ku_00017/data/raw/......./ucdp_views_priogrid_month.csv.zip'\n",
    "\n",
    "    if os.path.isfile(path_views) == True:\n",
    "\n",
    "        df_views = pd.read_csv(path_views)\n",
    "\n",
    "    else: \n",
    "        print('Beginning file download ViEWS...')\n",
    "        \n",
    "        url_views = 'https://views.pcr.uu.se/download/datasets/ucdp_views_priogrid_month.csv.zip'\n",
    "        urllib.request.urlretrieve(url_views, path_views)\n",
    "        df_views = pd.read_csv(path_views)\n",
    "\n",
    "    df_views.rename(columns= {'pg_id':'gid'}, inplace = True)\n",
    "\n",
    "    to_drop = ['id','ged_dummy_sb', 'ged_count_sb', 'ged_dummy_ns', 'ged_count_ns', \n",
    "            'ged_best_ns', 'ged_dummy_os', 'ged_count_os', 'ged_best_os']\n",
    "\n",
    "    df_views.drop(columns=to_drop, inplace = True)\n",
    "\n",
    "\n",
    "    # just to save ram on local !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    sub_years = sorted(df_views['year'].unique())[:4]\n",
    "    df_views = df_views[df_views['year'].isin(sub_years)]\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    return df_views\n",
    "\n",
    "\n",
    "def monthly_grid(prio_grid, yearly_df):\n",
    "\n",
    "    years = [sorted(yearly_df['year'].unique())] * prio_grid.shape[0]\n",
    "    months = [list(np.arange(1, 13))] * prio_grid.shape[0]\n",
    "\n",
    "    prio_grid['year'] = years\n",
    "    prio_grid['month'] = months\n",
    "\n",
    "    prio_grid = prio_grid.explode('year').reset_index(drop=True) \n",
    "    prio_grid = prio_grid.explode('month').reset_index(drop=True) \n",
    "\n",
    "    prio_grid['year'] = prio_grid['year'].astype(int)\n",
    "    prio_grid['month'] = prio_grid['month'].astype(int)\n",
    "\n",
    "    return prio_grid\n",
    "\n",
    "\n",
    "def merge_grid_views(prio_grid, df_views):\n",
    "    \n",
    "    merge_on = list(set.intersection(set(prio_grid.columns.unique()),set(df_views.columns.unique())))\n",
    "    merged_df = pd.merge(prio_grid, df_views, how = 'left', on = merge_on)\n",
    "\n",
    "    merged_df.fillna({'ged_best_sb' : 0, 'gwcode' : 0}, inplace = True) # for gwno 0 is no country\n",
    "    merged_df.fillna({'in_ucdp' : False}, inplace = True)\n",
    "\n",
    "    merged_df['log_best'] = np.log(merged_df['ged_best_sb'] + 1)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n",
    "def add_month_id(prio_grid):\n",
    "\n",
    "    prio_grid['year_month'] = prio_grid['year'].astype(str) + '_' + prio_grid['month'].astype(str) \n",
    "\n",
    "    ts = prio_grid['year_month'].unique()\n",
    "    n_ts = len(ts)\n",
    "    month_ids = np.arange(109, n_ts + 109, 1)\n",
    "    month_id_df = pd.DataFrame({'year_month' : ts, 'month_id': month_ids})\n",
    "    prio_grid = prio_grid.merge(month_id_df, on = 'year_month', how = 'left')\n",
    "\n",
    "    prio_grid.drop(columns=['year_month'], inplace= True)\n",
    "\n",
    "    return prio_grid\n",
    "\n",
    "\n",
    "def get_views_sub(merged_df, df_views):\n",
    "\n",
    "    africa_gids = df_views['gid'].unique()\n",
    "\n",
    "    max_coords = merged_df[merged_df['gid'].isin(africa_gids)][['xcoord', 'ycoord']].max() + (1,3.25) # get both dim to 180\n",
    "    min_coords = merged_df[merged_df['gid'].isin(africa_gids)][['xcoord', 'ycoord']].min() - (1,3)\n",
    "\n",
    "    mask1 = ((merged_df['xcoord'] < max_coords[0]) & (merged_df['xcoord'] > min_coords[0]) & (merged_df['ycoord'] < max_coords[1]) & (merged_df['ycoord'] > min_coords[1]))\n",
    "    views_subset = merged_df[mask1].copy()\n",
    "    col_to_change = views_subset.columns[7:18]\n",
    "    #views_subset.loc[~views_subset['gid'].isin(africa_gids), col_to_change] = 0\n",
    "    views_subset.reset_index(inplace=True, drop = True)\n",
    "\n",
    "    return views_subset\n",
    "\n",
    "\n",
    "\n",
    "# this\n",
    "\n",
    "def make_volumn(df):\n",
    "\n",
    "    # we start with wat we know - but there is no reason not to try with more down til line.\n",
    "\n",
    "    #sub_df = df[['gid', 'xcoord', 'ycoord', 'month_id', 'best', 'low', 'high', 'log_best', 'log_low', 'log_high', 'gwno']].copy() # remove the everything also the geo col.\n",
    "    sub_df = df[['gid', 'xcoord', 'ycoord', 'month_id', 'ged_best_sb', 'log_best', 'gwcode']].copy() # remove the everything also the geo col.\n",
    "\n",
    "    sub_df_sorted = sub_df.sort_values(['month_id', 'ycoord', 'xcoord'], ascending = [True, False, True])\n",
    "\n",
    "    # try to keep the jazz\n",
    "    #grid_ucdpS = grid_ucdpS[['gid','best', 'low',  'high', 'log_best', 'log_low', 'log_high']].copy() # remove the everything also the geo col. But keep gid. Why not.\n",
    "\n",
    "    x_dim = sub_df['xcoord'].unique().shape[0]\n",
    "    y_dim = sub_df['ycoord'].unique().shape[0]\n",
    "    z_dim = sub_df['month_id'].unique().shape[0]\n",
    "\n",
    "    ucpd_vol = np.array(sub_df_sorted).reshape((z_dim, y_dim, x_dim, -1))\n",
    "\n",
    "    return ucpd_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded\n",
      "file already downloaded\n"
     ]
    }
   ],
   "source": [
    "prio_grid = get_prio_shape()\n",
    "gwno = get_gwno()\n",
    "ucdp = get_ucdp()\n",
    "df_views = get_views_data()\n",
    "prio_grid = monthly_grid(prio_grid, df_views)\n",
    "prio_grid = add_month_id(prio_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merge_grid_views(prio_grid, df_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 180, 180, 7)\n",
      "(48, 360, 720, 7)\n"
     ]
    }
   ],
   "source": [
    "views_subset = get_views_sub(merged_df, df_views)\n",
    "\n",
    "views_vol = make_volumn(views_subset)\n",
    "print(views_vol.shape)\n",
    "\n",
    "worlds_vol = make_volumn(merged_df)\n",
    "print(worlds_vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, type, folder):\n",
    "\n",
    "    map_dir = f'/home/simon/Documents/Articles/ConflictNet/presentation/timelaps/{folder}/'\n",
    "\n",
    "    for i in df['month_id'].unique():\n",
    "\n",
    "        if type == 'grid':\n",
    "            data = df[df['month_id'] == i]\n",
    "\n",
    "        elif type == 'land':\n",
    "            data =  df[(df['month_id'] == i) & (df['gwcode'] != 0)]\n",
    "\n",
    "        x = data['xcoord']\n",
    "        y = data['ycoord']\n",
    "        z = data['log_best']\n",
    "\n",
    "        plt.figure(figsize= [10,9])\n",
    "        plt.scatter(x, y, c=z, s=5, marker = 's', cmap = 'rainbow', vmin=df['log_best'].min() , vmax=df['log_best'].max())\n",
    "\n",
    "        fig_title = f'df_{str(i).zfill(3)}'\n",
    "\n",
    "        plt.title(fig_title)\n",
    "        plt.savefig(map_dir + fig_title + '.JPG', bbox_inches=\"tight\")\n",
    "        plt.cla() # idk if this is also needed..\n",
    "        plt.close('all') # so they do not display or take up mem\n",
    "\n",
    "    print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vol(vol, type, folder):\n",
    "\n",
    "    map_dir = f'/home/simon/Documents/Articles/ConflictNet/presentation/timelaps/{folder}/'\n",
    "    \n",
    "    for i in range(vol.shape[0]):\n",
    "\n",
    "        if type == 'grid':\n",
    "            data = vol[i,:,:,5]\n",
    "\n",
    "        elif type == 'land':\n",
    "            data = np.ma.masked_where((vol[i,:,:,6] == 0), vol[i,:,:,5])\n",
    "\n",
    "        plt.imshow(data, cmap = 'rainbow', vmin=vol[-1,:,:,5].min() , vmax=vol[-1,:,:,5].max())\n",
    "        #plt.show()\n",
    "\n",
    "        fig_title = f'vol_{str(i).zfill(3)}'\n",
    "\n",
    "        plt.title(fig_title)\n",
    "        plt.savefig(map_dir + fig_title + '.JPG', bbox_inches=\"tight\")\n",
    "        plt.cla() # idk if this is also needed..\n",
    "        plt.close('all') # so they do not display or take up mem\n",
    "\n",
    "    print('done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done..\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "plot_vol(views_vol, 'grid', 'views_grid')\n",
    "plot_vol(views_vol, 'land', 'views_land')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done..\n",
      "done..\n"
     ]
    }
   ],
   "source": [
    "plot_df(views_subset, 'grid', 'views_grid_df')\n",
    "plot_df(views_subset, 'land', 'views_land_df')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('geo_env_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5129632b36db574984207cd0a6a7eba6bc5bd4272ef35f5fb4074faf0a719fbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
